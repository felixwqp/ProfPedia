Discussion of "2004 IMS Medallion Lecture: Local Rademacher complexities  and oracle inequalities in risk minimization" by V. Koltchinskii

  Discussion of "2004 IMS Medallion Lecture: Local Rademacher complexities andoracle inequalities in risk minimization" by V. Koltchinskii [arXiv:0708.0083]

Local Rademacher complexities

  We propose new bounds on the error of learning algorithms in terms of adata-dependent notion of complexity. The estimates we establish give optimalrates and are based on a local and empirical version of Rademacher averages, inthe sense that the Rademacher averages are computed from the data, on a subsetof functions with small empirical error. We present some applications toclassification and prediction with convex function classes, and with kernelclasses in particular.

REGAL: A Regularization based Algorithm for Reinforcement Learning in  Weakly Communicating MDPs

  We provide an algorithm that achieves the optimal regret rate in an unknownweakly communicating Markov Decision Process (MDP). The algorithm proceeds inepisodes where, in each episode, it picks a policy using regularization basedon the span of the optimal bias vector. For an MDP with S states and A actionswhose optimal bias vector has span bounded by H, we show a regret bound of~O(HSpAT). We also relate the span to various diameter-like quantitiesassociated with the MDP, demonstrating how our results improve on previousregret bounds.

Photon-number superselection and the entangled coherent-state  representation

  We introduce the entangled coherent state representation, which provides apowerful technique for efficiently and elegantly describing and analyzingquantum optics sources and detectors while respecting the photon numbersuperselection rule that is satisfied by all known quantum optics experiments.We apply the entangled coherent state representation to elucidate and resolvethe longstanding puzzles of the coherence of a laser output field, interferencebetween two number states, and dichotomous interpretations of quantumteleportation of coherent states.

Comment on "Support Vector Machines with Applications"

  Comment on "Support Vector Machines with Applications" [math.ST/0612817]

Quantum quincunx in cavity quantum electrodynamics

  We introduce the quantum quincunx, which physically demonstrates the quantumwalk and is analogous to Galton's quincunx for demonstrating the random walk.In contradistinction to the theoretical studies of quantum walks overorthogonal lattice states, we introduce quantum walks over nonorthogonallattice states (specifically, coherent states on a circle) to demonstrate thatthe key features of a quantum walk are observable albeit for strict parameterranges. A quantum quincunx may be realized with current cavity quantumelectrodynamics capabilities, and precise control over decoherence in suchexperiments allows a remarkable decrease in the position noise, or spread, withincreasing decoherence.

A Unifying View of Multiple Kernel Learning

  Recent research on multiple kernel learning has lead to a number ofapproaches for combining kernels in regularized risk minimization. The proposedapproaches include different formulations of objectives and varyingregularization strategies. In this paper we present a unifying generaloptimization criterion for multiple kernel learning and show how existingformulations are subsumed as special cases. We also derive the criterion's dualrepresentation, which is suitable for general smooth optimization algorithms.Finally, we evaluate multiple kernel learning in this framework analyticallyusing a Rademacher complexity bound on the generalization error and empiricallyin a set of experiments.

Information-theoretic lower bounds on the oracle complexity of  stochastic convex optimization

  Relative to the large literature on upper bounds on complexity of convexoptimization, lesser attention has been paid to the fundamental hardness ofthese problems. Given the extensive use of convex optimization in machinelearning and statistics, gaining an understanding of these complexity-theoreticissues is important. In this paper, we study the complexity of stochasticconvex optimization in an oracle model of computation. We improve upon knownresults and obtain tight minimax complexity estimates for various functionclasses.

Blackwell Approachability and Low-Regret Learning are Equivalent

  We consider the celebrated Blackwell Approachability Theorem for two-playergames with vector payoffs. We show that Blackwell's result is equivalent, viaefficient reductions, to the existence of "no-regret" algorithms for OnlineLinear Optimization. Indeed, we show that any algorithm for one such problemcan be efficiently converted into an algorithm for the other. We provide auseful application of this reduction: the first efficient algorithm forcalibrated forecasting.

Oracle inequalities for computationally adaptive model selection

  We analyze general model selection procedures using penalized empirical lossminimization under computational constraints. While classical model selectionapproaches do not consider computational aspects of performing model selection,we argue that any practical model selection procedure must not only trade offestimation and approximation error, but also the computational effort requiredto compute empirical minimizers for different function classes. We provide aframework for analyzing such problems, and we give algorithms for modelselection under a computational budget. These algorithms satisfy oracleinequalities that show that the risk of the selected model is not much worsethan if we had devoted all of our omputational budget to the optimal functionclass.

Online Learning in Markov Decision Processes with Adversarially Chosen  Transition Probability Distributions

  We study the problem of learning Markov decision processes with finite stateand action spaces when the transition probability distributions and lossfunctions are chosen adversarially and are allowed to change with time. Weintroduce an algorithm whose regret with respect to any policy in a comparisonclass grows as the square root of the number of rounds of the game, providedthe transition probabilities satisfy a uniform mixing condition. Our approachis efficient as long as the comparison class is polynomial and we can computeexpectations over sample paths for each policy. Designing an efficientalgorithm with small regret for the general case remains an open problem.

Hit-and-Run for Sampling and Planning in Non-Convex Spaces

  We propose the Hit-and-Run algorithm for planning and sampling problems innon-convex spaces. For sampling, we show the first analysis of the Hit-and-Runalgorithm in non-convex spaces and show that it mixes fast as long as certainsmoothness conditions are satisfied. In particular, our analysis reveals anintriguing connection between fast mixing and the existence of smoothmeasure-preserving mappings from a convex space to the non-convex space. Forplanning, we show advantages of Hit-and-Run compared to state-of-the-artplanning methods such as Rapidly-Exploring Random Trees.

Gen-Oja: A Simple and Efficient Algorithm for Streaming Generalized  Eigenvector Computation

  In this paper, we study the problems of principal Generalized Eigenvectorcomputation and Canonical Correlation Analysis in the stochastic setting. Wepropose a simple and efficient algorithm, Gen-Oja, for these problems. We provethe global convergence of our algorithm, borrowing ideas from the theory offast-mixing Markov chains and two-time-scale stochastic approximation, showingthat it achieves the optimal rate of convergence. In the process, we developtools for understanding stochastic processes with Markovian noise which mightbe of independent interest.

Quantitative Central Limit Theorems for Discrete Stochastic Processes

  In this paper, we establish a generalization of the classical Central LimitTheorem for a family of stochastic processes that includes stochastic gradientdescent and related gradient-based algorithms. Under certain regularityassumptions, we show that the iterates of these stochastic processes convergeto an invariant distribution at a rate of $O\lrp{1/\sqrt{k}}$ where $k$ is thenumber of steps; this rate is provably tight.

Fast Mean Estimation with Sub-Gaussian Rates

  We propose an estimator for the mean of a random vector in $\mathbb{R}^d$that can be computed in time $O(n^4+n^2d)$ for $n$ i.i.d.~samples and that haserror bounds matching the sub-Gaussian case. The only assumptions we make aboutthe data distribution are that it has finite mean and covariance; inparticular, we make no assumptions about higher-order moments. Like thepolynomial time estimator introduced by Hopkins, 2018, which is based on thesum-of-squares hierarchy, our estimator achieves optimal statistical efficiencyin this challenging setting, but it has a significantly faster runtime and asimpler analysis.

Sharp Convergence Rates for Langevin Dynamics in the Nonconvex Setting

  We study the problem of sampling from a distribution where the negativelogarithm of the target density is $L$-smooth everywhere and $m$-stronglyconvex outside a ball of radius $R$, but potentially non-convex inside thisball. We study both overdamped and underdamped Langevin MCMC and prove upperbounds on the time required to obtain a sample from a distribution that iswithin $\epsilon$ of the target distribution in $1$-Wasserstein distance. Forthe first-order method (overdamped Langevin MCMC), the time complexity is$\tilde{\mathcal{O}}\left(e^{cLR^2}\frac{d}{\epsilon^2}\right)$, where $d$ isthe dimension of the underlying space. For the second-order method (underdampedLangevin MCMC), the time complexity is$\tilde{\mathcal{O}}\left(e^{cLR^2}\frac{\sqrt{d}}{\epsilon}\right)$ for someexplicit positive constant $c$. Surprisingly, the convergence rate is onlypolynomial in the dimension $d$ and the target accuracy $\epsilon$. It ishowever exponential in the problem parameter $LR^2$, which is a measure ofnon-logconcavity of the target distribution.

Margin-adaptive model selection in statistical learning

  A classical condition for fast learning rates is the margin condition, firstintroduced by Mammen and Tsybakov. We tackle in this paper the problem ofadaptivity to this condition in the context of model selection, in a generallearning framework. Actually, we consider a weaker version of this conditionthat allows one to take into account that learning within a small model can bemuch easier than within a large one. Requiring this "strong margin adaptivity"makes the model selection problem more challenging. We first prove, in ageneral framework, that some penalization procedures (including localRademacher complexities) exhibit this adaptivity when the models are nested.Contrary to previous results, this holds with penalties that only depend on thedata. Our second main result is that strong margin adaptivity is not alwayspossible when the models are not nested: for every model selection procedure(even a randomized one), there is a problem for which it does not demonstratestrong margin adaptivity.

A Stochastic View of Optimal Regret through Minimax Duality

  We study the regret of optimal strategies for online convex optimizationgames. Using von Neumann's minimax theorem, we show that the optimal regret inthis adversarial setting is closely related to the behavior of the empiricalminimization algorithm in a stochastic process setting: it is equal to themaximum, over joint distributions of the adversary's action sequence, of thedifference between a sum of minimal expected losses and the minimal empiricalloss. We show that the optimal regret has a natural geometric interpretation,since it can be viewed as the gap in Jensen's inequality for a concavefunctional--the minimizer over the player's actions of expected loss--definedon a set of probability distributions. We use this expression to obtain upperand lower bounds on the regret of an optimal strategy for a variety of onlinelearning problems. Our method provides upper bounds without the need toconstruct a learning algorithm; the lower bounds provide explicit optimalstrategies for the adversary.

A Learning-Based Approach to Reactive Security

  Despite the conventional wisdom that proactive security is superior toreactive security, we show that reactive security can be competitive withproactive security as long as the reactive defender learns from past attacksinstead of myopically overreacting to the last attack. Our game-theoretic modelfollows common practice in the security literature by making worst-caseassumptions about the attacker: we grant the attacker complete knowledge of thedefender's strategy and do not require the attacker to act rationally. In thismodel, we bound the competitive ratio between a reactive defense algorithm(which is inspired by online learning theory) and the best fixed proactivedefense. Additionally, we show that, unlike proactive defenses, this reactivestrategy is robust to a lack of information about the attacker's incentives andknowledge.

Randomized Smoothing for Stochastic Optimization

  We analyze convergence rates of stochastic optimization procedures fornon-smooth convex optimization problems. By combining randomized smoothingtechniques with accelerated gradient methods, we obtain convergence rates ofstochastic optimization procedures, both in expectation and with highprobability, that have optimal dependence on the variance of the gradientestimates. To the best of our knowledge, these are the first variance-basedrates for non-smooth optimization. We give several applications of our resultsto statistical estimation problems, and provide experimental results thatdemonstrate the effectiveness of the proposed algorithms. We also describe howa combination of our algorithm with recent work on decentralized optimizationyields a distributed stochastic optimization algorithm that is order-optimal.

Linear Programming for Large-Scale Markov Decision Problems

  We consider the problem of controlling a Markov decision process (MDP) with alarge state space, so as to minimize average cost. Since it is intractable tocompete with the optimal policy for large scale problems, we pursue the moremodest goal of competing with a low-dimensional family of policies. We use thedual linear programming formulation of the MDP average cost problem, in whichthe variable is a stationary distribution over state-action pairs, and weconsider a neighborhood of a low-dimensional subset of the set of stationarydistributions (defined in terms of state-action features) as the comparisonclass. We propose two techniques, one based on stochastic convex optimization,and one based on constraint sampling. In both cases, we give bounds that showthat the performance of our algorithms approaches the best achievable by anypolicy in the comparison class. Most importantly, these results depend on thesize of the comparison class, but not on the size of the state space.Preliminary experiments show the effectiveness of the proposed algorithms in aqueuing application.

FLAG n' FLARE: Fast Linearly-Coupled Adaptive Gradient Methods

  We consider first order gradient methods for effectively optimizing acomposite objective in the form of a sum of smooth and, potentially, non-smoothfunctions. We present accelerated and adaptive gradient methods, called FLAGand FLARE, which can offer the best of both worlds. They can achieve theoptimal convergence rate by attaining the optimal first-order oracle complexityfor smooth convex optimization. Additionally, they can adaptively andnon-uniformly re-scale the gradient direction to adapt to the limited curvatureavailable and conform to the geometry of the domain. We show theoretically andempirically that, through the compounding effects of acceleration andadaptivity, FLAG and FLARE can be highly effective for many data fitting andmachine learning applications.

Convergence of Langevin MCMC in KL-divergence

  Langevin diffusion is a commonly used tool for sampling from a givendistribution. In this work, we establish that when the target density $p^*$ issuch that $\log p^*$ is $L$ smooth and $m$ strongly convex, discrete Langevindiffusion produces a distribution $p$ with $KL(p||p^*)\leq \epsilon$ in$\tilde{O}(\frac{d}{\epsilon})$ steps, where $d$ is the dimension of the samplespace. We also study the convergence rate when the strong-convexity assumptionis absent. By considering the Langevin diffusion as a gradient flow in thespace of probability distributions, we obtain an elegant analysis that appliesto the stronger property of convergence in KL-divergence and gives aconceptually simpler proof of the best-known convergence results in weakermetrics.

Underdamped Langevin MCMC: A non-asymptotic analysis

  We study the underdamped Langevin diffusion when the log of the targetdistribution is smooth and strongly concave. We present a MCMC algorithm basedon its discretization and show that it achieves $\varepsilon$ error (in2-Wasserstein distance) in $\mathcal{O}(\sqrt{d}/\varepsilon)$ steps. This is asignificant improvement over the best known rate for overdamped Langevin MCMC,which is $\mathcal{O}(d/\varepsilon^2)$ steps under the samesmoothness/concavity assumptions.  The underdamped Langevin MCMC scheme can be viewed as a version ofHamiltonian Monte Carlo (HMC) which has been observed to outperform overdampedLangevin MCMC methods in a number of application areas. We provide quantitativerates that support this empirical wisdom.

Acceleration and Averaging in Stochastic Mirror Descent Dynamics

  We formulate and study a general family of (continuous-time) stochasticdynamics for accelerated first-order minimization of smooth convex functions.Building on an averaging formulation of accelerated mirror descent, we proposea stochastic variant in which the gradient is contaminated by noise, and studythe resulting stochastic differential equation. We prove a bound on the rate ofchange of an energy function associated with the problem, then use it to deriveestimates of convergence rates of the function values, (a.s. and inexpectation) both for persistent and asymptotically vanishing noise. We discussthe interaction between the parameters of the dynamics (learning rate andaveraging weights) and the covariation of the noise process, and show, inparticular, how the asymptotic rate of covariation affects the choice ofparameters and, ultimately, the convergence rate.

On the Theory of Variance Reduction for Stochastic Gradient Monte Carlo

  We provide convergence guarantees in Wasserstein distance for a variety ofvariance-reduction methods: SAGA Langevin diffusion, SVRG Langevin diffusionand control-variate underdamped Langevin diffusion. We analyze these methodsunder a uniform set of assumptions on the log-posterior distribution, assumingit to be smooth, strongly convex and Hessian Lipschitz. This is achieved by anew proof technique combining ideas from finite-sum optimization and theanalysis of sampling methods. Our sharp theoretical bounds allow us to identifyregimes of interest where each method performs better than the others. Ourtheory is verified with experiments on real-world and synthetic datasets.

Online learning with kernel losses

  We present a generalization of the adversarial linear bandits framework,where the underlying losses are kernel functions (with an associatedreproducing kernel Hilbert space) rather than linear functions. We study aversion of the exponential weights algorithm and bound its regret in thissetting. Under conditions on the eigendecay of the kernel we provide a sharpcharacterization of the regret for this algorithm. When we have polynomialeigendecay $\mu_j \le \mathcal{O}(j^{-\beta})$, we find that the regret isbounded by $\mathcal{R}_n \le \mathcal{O}(n^{\beta/(2(\beta-1))})$; while underthe assumption of exponential eigendecay $\mu_j \le \mathcal{O}(e^{-\beta j})$, we get an even tighter bound on the regret $\mathcal{R}_n \le\mathcal{O}(n^{1/2}\log(n)^{1/2})$. We also study the full information settingwhen the underlying losses are kernel functions and present an adaptedexponential weights algorithm and a conditional gradient descent algorithm.

Best of many worlds: Robust model selection for online supervised  learning

  We introduce algorithms for online, full-information prediction that arecompetitive with contextual tree experts of unknown complexity, in bothprobabilistic and adversarial settings. We show that by incorporating aprobabilistic framework of structural risk minimization into existing adaptivealgorithms, we can robustly learn not only the presence of stochastic structurewhen it exists (leading to constant as opposed to $\mathcal{O}(\sqrt{T})$regret), but also the correct model order. We thus obtain regret bounds thatare competitive with the regret of an optimal algorithm that possesses strongside information about both the complexity of the optimal contextual treeexpert and whether the process generating the data is stochastic oradversarial. These are the first constructive guarantees on simultaneousadaptivity to the model and the presence of stochasticity.

Derivative-Free Methods for Policy Optimization: Guarantees for Linear  Quadratic Systems

  We study derivative-free methods for policy optimization over the class oflinear policies. We focus on characterizing the convergence rate of thesemethods when applied to linear-quadratic systems, and study various settings ofdriving noise and reward feedback. We show that these methods provably convergeto within any pre-specified tolerance of the optimal policy with a number ofzero-order evaluations that is an explicit polynomial of the error tolerance,dimension, and curvature properties of the problem. Our analysis reveals someinteresting differences between the settings of additive driving noise andrandom initialization, as well as the settings of one-point and two-pointreward feedback. Our theory is corroborated by extensive simulations ofderivative-free methods on these systems. Along the way, we derive convergencerates for stochastic zero-order optimization algorithms when applied to acertain class of non-convex problems.

Large-Scale Markov Decision Problems via the Linear Programming Dual

  We consider the problem of controlling a fully specified Markov decisionprocess (MDP), also known as the planning problem, when the state space is verylarge and calculating the optimal policy is intractable. Instead, we pursue themore modest goal of optimizing over some small family of policies.Specifically, we show that the family of policies associated with alow-dimensional approximation of occupancy measures yields a tractableoptimization. Moreover, we propose an efficient algorithm, scaling with thesize of the subspace but not the state space, that is able to find a policywith low excess loss relative to the best policy in this class. To the best ofour knowledge, such results did not exist in the literature previously. Webound excess loss in the average cost and discounted cost cases, which aretreated separately. Preliminary experiments show the effectiveness of theproposed algorithms in a queueing application.

Testing Markov Chains without Hitting

  We study the problem of identity testing of markov chains. In this setting,we are given access to a single trajectory from a markov chain with unknowntransition matrix $Q$ and the goal is to determine whether $Q = P$ for someknown matrix $P$ or $\text{Dist}(P, Q) \geq \epsilon$ where $\text{Dist}$ issuitably defined. In recent work by Daskalakis, Dikkala and Gravin, 2018, itwas shown that it is possible to distinguish between the two cases provided thelength of the observed trajectory is at least super-linear in the hitting timeof $P$ which may be arbitrarily large.  In this paper, we propose an algorithm that avoids this dependence on hittingtime thus enabling efficient testing of markov chains even in cases where it isinfeasible to observe every state in the chain. Our algorithm is based oncombining classical ideas from approximation algorithms with techniques for thespectral analysis of markov chains.

Nearly-tight VC-dimension and pseudodimension bounds for piecewise  linear neural networks

  We prove new upper and lower bounds on the VC-dimension of deep neuralnetworks with the ReLU activation function. These bounds are tight for almostthe entire range of parameters. Letting $W$ be the number of weights and $L$ bethe number of layers, we prove that the VC-dimension is $O(W L \log(W))$, andprovide examples with VC-dimension $\Omega( W L \log(W/L) )$. This improvesboth the previously known upper bounds and lower bounds. In terms of the number$U$ of non-linear units, we prove a tight bound $\Theta(W U)$ on theVC-dimension. All of these bounds generalize to arbitrary piecewise linearactivation functions, and also hold for the pseudodimensions of these functionclasses.  Combined with previous results, this gives an intriguing range ofdependencies of the VC-dimension on depth for networks with differentnon-linearities: there is no dependence for piecewise-constant, lineardependence for piecewise-linear, and no more than quadratic dependence forgeneral piecewise-polynomial.

Learning in a Large Function Space: Privacy-Preserving Mechanisms for  SVM Learning

  Several recent studies in privacy-preserving learning have considered thetrade-off between utility or risk and the level of differential privacyguaranteed by mechanisms for statistical query processing. In this paper westudy this trade-off in private Support Vector Machine (SVM) learning. Wepresent two efficient mechanisms, one for the case of finite-dimensionalfeature mappings and one for potentially infinite-dimensional feature mappingswith translation-invariant kernels. For the case of translation-invariantkernels, the proposed mechanism minimizes regularized empirical risk in arandom Reproducing Kernel Hilbert Space whose kernel uniformly approximates thedesired kernel with high probability. This technique, borrowed from large-scalelearning, allows the mechanism to respond with a finite encoding of theclassifier, even when the function class is of infinite VC dimension.Differential privacy is established using a proof technique from algorithmicstability. Utility--the mechanism's response function is pointwiseepsilon-close to non-private SVM with probability 1-delta--is proven byappealing to the smoothness of regularized empirical risk minimization withrespect to small perturbations to the feature mapping. We conclude with a lowerbound on the optimal differential privacy of the SVM. This negative resultstates that for any delta, no mechanism can be simultaneously(epsilon,delta)-useful and beta-differentially private for small epsilon andsmall beta.

Bounding Embeddings of VC Classes into Maximum Classes

  One of the earliest conjectures in computational learning theory-the SampleCompression conjecture-asserts that concept classes (equivalently set systems)admit compression schemes of size linear in their VC dimension. To-date thisstatement is known to be true for maximum classes---those that possess maximumcardinality for their VC dimension. The most promising approach to positivelyresolving the conjecture is by embedding general VC classes into maximumclasses without super-linear increase to their VC dimensions, as suchembeddings would extend the known compression schemes to all VC classes. Weshow that maximum classes can be characterised by a local-connectivity propertyof the graph obtained by viewing the class as a cubical complex. This geometriccharacterisation of maximum VC classes is applied to prove a negative embeddingresult which demonstrates VC-d classes that cannot be embedded in any maximumclass of VC dimension lower than 2d. On the other hand, we show that every VC-dclass C embeds in a VC-(d+D) maximum class where D is the deficiency of C,i.e., the difference between the cardinalities of a maximum VC-d class and ofC. For VC-2 classes in binary n-cubes for 4 <= n <= 6, we give best possibleresults on embedding into maximum classes. For some special classes of Booleanfunctions, relationships with maximum classes are investigated. Finally we givea general recursive procedure for embedding VC-d classes into VC-(d+k) maximumclasses for smallest k.

RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning

  Deep reinforcement learning (deep RL) has been successful in learningsophisticated behaviors automatically; however, the learning process requires ahuge number of trials. In contrast, animals can learn new tasks in just a fewtrials, benefiting from their prior knowledge about the world. This paper seeksto bridge this gap. Rather than designing a "fast" reinforcement learningalgorithm, we propose to represent it as a recurrent neural network (RNN) andlearn it from data. In our proposed method, RL$^2$, the algorithm is encoded inthe weights of the RNN, which are learned slowly through a general-purpose("slow") RL algorithm. The RNN receives all information a typical RL algorithmwould receive, including observations, actions, rewards, and termination flags;and it retains its state across episodes in a given Markov Decision Process(MDP). The activations of the RNN store the state of the "fast" RL algorithm onthe current (previously unseen) MDP. We evaluate RL$^2$ experimentally on bothsmall-scale and large-scale problems. On the small-scale side, we train it tosolve randomly generated multi-arm bandit problems and finite MDPs. AfterRL$^2$ is trained, its performance on new MDPs is close to human-designedalgorithms with optimality guarantees. On the large-scale side, we test RL$^2$on a vision-based navigation task and show that it scales up tohigh-dimensional problems.

Recovery Guarantees for One-hidden-layer Neural Networks

  In this paper, we consider regression problems with one-hidden-layer neuralnetworks (1NNs). We distill some properties of activation functions that leadto $\mathit{local~strong~convexity}$ in the neighborhood of the ground-truthparameters for the 1NN squared-loss objective. Most popular nonlinearactivation functions satisfy the distilled properties, including rectifiedlinear units (ReLUs), leaky ReLUs, squared ReLUs and sigmoids. For activationfunctions that are also smooth, we show $\mathit{local~linear~convergence}$guarantees of gradient descent under a resampling rule. For homogeneousactivations, we show tensor methods are able to initialize the parameters tofall into the local strong convexity region. As a result, tensor initializationfollowed by gradient descent is guaranteed to recover the ground truth withsample complexity $ d \cdot \log(1/\epsilon) \cdot \mathrm{poly}(k,\lambda )$and computational complexity $n\cdot d \cdot \mathrm{poly}(k,\lambda) $ forsmooth homogeneous activations with high probability, where $d$ is thedimension of the input, $k$ ($k\leq d$) is the number of hidden nodes,$\lambda$ is a conditioning property of the ground-truth parameter matrixbetween the input layer and the hidden layer, $\epsilon$ is the targetedprecision and $n$ is the number of samples. To the best of our knowledge, thisis the first work that provides recovery guarantees for 1NNs with both samplecomplexity and computational complexity $\mathit{linear}$ in the inputdimension and $\mathit{logarithmic}$ in the precision.

Alternating minimization for dictionary learning with random  initialization

  We present theoretical guarantees for an alternating minimization algorithmfor the dictionary learning/sparse coding problem. The dictionary learningproblem is to factorize vector samples $y^{1},y^{2},\ldots, y^{n}$ into anappropriate basis (dictionary) $A^*$ and sparse vectors $x^{1*},\ldots,x^{n*}$.Our algorithm is a simple alternating minimization procedure that switchesbetween $\ell_1$ minimization and gradient descent in alternate steps.Dictionary learning and specifically alternating minimization algorithms fordictionary learning are well studied both theoretically and empirically.However, in contrast to previous theoretical analyses for this problem, wereplace the condition on the operator norm (that is, the largest magnitudesingular value) of the true underlying dictionary $A^*$ with a condition on thematrix infinity norm (that is, the largest magnitude term). This not onlyallows us to get convergence rates for the error of the estimated dictionarymeasured in the matrix infinity norm, but also ensures that a randominitialization will provably converge to the global optimum. Our guarantees areunder a reasonable generative model that allows for dictionaries with growingoperator norms, and can handle an arbitrary level of overcompleteness, whilehaving sparsity that is information theoretically optimal. We also establishupper bounds on the sample complexity of our algorithm.

Representing smooth functions as compositions of near-identity functions  with implications for deep network optimization

  We show that any smooth bi-Lipschitz $h$ can be represented exactly as acomposition $h_m \circ ... \circ h_1$ of functions $h_1,...,h_m$ that are closeto the identity in the sense that each $\left(h_i-\mathrm{Id}\right)$ isLipschitz, and the Lipschitz constant decreases inversely with the number $m$of functions composed. This implies that $h$ can be represented to any accuracyby a deep residual network whose nonlinear layers compute functions with asmall Lipschitz constant. Next, we consider nonlinear regression with acomposition of near-identity nonlinear maps. We show that, regarding Fr\'echetderivatives with respect to the $h_1,...,h_m$, any critical point of aquadratic criterion in this near-identity region must be a global minimizer. Incontrast, if we consider derivatives with respect to parameters of a fixed-sizeresidual network with sigmoid activation functions, we show that there arenear-identity critical points that are suboptimal, even in the realizable case.Informally, this means that functional gradient methods for residual networkscannot get stuck at suboptimal critical points corresponding to near-identitylayers, whereas parametric gradient methods for sigmoidal residual networkssuffer from suboptimal critical points in the near-identity region.

A simple parameter-free and adaptive approach to optimization under a  minimal local smoothness assumption

  We study the problem of optimizing a function under a \emph{budgeted numberof evaluations}. We only assume that the function is \emph{locally} smootharound one of its global optima. The difficulty of optimization is measured interms of 1) the amount of \emph{noise} $b$ of the function evaluation and 2)the local smoothness, $d$, of the function. A smaller $d$ results in smalleroptimization error. We come with a new, simple, and parameter-free approach.First, for all values of $b$ and $d$, this approach recovers at least thestate-of-the-art regret guarantees. Second, our approach additionally obtainsthese results while being \textit{agnostic} to the values of both $b$ and $d$.This leads to the first algorithm that naturally adapts to an \textit{unknown}range of noise $b$ and leads to significant improvements in a moderate andlow-noise regime. Third, our approach also obtains a remarkable improvementover the state-of-the-art SOO algorithm when the noise is very low whichincludes the case of optimization under deterministic feedback ($b=0$). There,under our minimal local smoothness assumption, this improvement is ofexponential magnitude and holds for a class of functions that covers the vastmajority of functions that practitioners optimize ($d=0$). We show that ouralgorithmic improvement is borne out in experiments as we empirically showfaster convergence on common benchmarks.

Gradient descent with identity initialization efficiently learns  positive definite linear transformations by deep residual networks

  We analyze algorithms for approximating a function $f(x) = \Phi x$ mapping$\Re^d$ to $\Re^d$ using deep linear neural networks, i.e. that learn afunction $h$ parameterized by matrices $\Theta_1,...,\Theta_L$ and defined by$h(x) = \Theta_L \Theta_{L-1} ... \Theta_1 x$. We focus on algorithms thatlearn through gradient descent on the population quadratic loss in the casethat the distribution over the inputs is isotropic.  We provide polynomial bounds on the number of iterations for gradient descentto approximate the least squares matrix $\Phi$, in the case where the initialhypothesis $\Theta_1 = ... = \Theta_L = I$ has excess loss bounded by a smallenough constant. On the other hand, we show that gradient descent fails toconverge for $\Phi$ whose distance from the identity is a larger constant, andwe show that some forms of regularization toward the identity in each layer donot help.  If $\Phi$ is symmetric positive definite, we show that an algorithm thatinitializes $\Theta_i = I$ learns an $\epsilon$-approximation of $f$ using anumber of updates polynomial in $L$, the condition number of $\Phi$, and$\log(d/\epsilon)$. In contrast, we show that if the least squares matrix$\Phi$ is symmetric and has a negative eigenvalue, then all members of a classof algorithms that perform gradient descent with identity initialization, andoptionally regularize toward the identity in each layer, fail to converge.  We analyze an algorithm for the case that $\Phi$ satisfies $u^{\top} \Phi u >0$ for all $u$, but may not be symmetric. This algorithm uses two regularizers:one that maintains the invariant $u^{\top} \Theta_L \Theta_{L-1} ... \Theta_1 u> 0$ for all $u$, and another that "balances" $\Theta_1, ..., \Theta_L$ so thatthey have the same singular values.

The Near-Infrared Sky Surveyor

  [NIRSS is one of three concepts that contributed to the Wide-Field InfraredSurvey Telescope (WFIRST) mission advocated by the Decadal Survey.] Operatingbeyond the reaches of the Earth's atmosphere, free of its limiting absorptionand thermal background, the Near-Infrared Sky Surveyor (NIRSS) will deeply mapthe entire sky at near-infrared wavelengths, thereby enabling new andfundamental discoveries ranging from the identification of extrasolar planetsto probing the reionization epoch by identifying thousands of quasars at z>10.NIRSS will directly address the NASA scientific objective of studying cosmicorigins by using a 1.5-meter telescope to reach full-sky 0.2 uJy (25.6 mag AB)sensitivities in four passbands from 1 to 4 microns in a 4-yr mission. At thethree shorter passbands (1 - 2.5 microns), the proposed depth is comparable tothe deepest pencil-beam surveys done to date and is 3000 times more sensitivethan the only previous all-sky near-infrared survey, 2MASS. At the longestpassband (3.5 micron), which is not feasible from the ground, NIRSS will be 500times more sensitive than WISE. NIRSS fills a pivotal gap in our knowledge ofthe celestial sphere, is a natural complement to WISE, and is well matched tothe next generation of deep (0.1 uJy), wide-area (>2 pi ster), ground-basedoptical surveys (LSST and Pan-Starrs). With the high thermal backgrounds ofground-based infrared observations, a near-infrared full sky survey at sub-uJysensitivity is only feasible from space.

The GRIFFIN Facility for Decay-Spectroscopy Studies at TRIUMF-ISAC

  Gamma-Ray Infrastructure For Fundamental Investigations of Nuclei, GRIFFIN,is a new high-efficiency $\gamma$-ray spectrometer designed for use in decayspectroscopy experiments with low-energy radioactive ion beams provided byTRIUMF's Isotope Separator and Accelerator (ISAC-I) facility. GRIFFIN iscomposed of sixteen Compton-suppressed large-volume clover-type high-puritygermanium (HPGe) $\gamma$-ray detectors combined with a suite of ancillarydetection systems and coupled to a custom digital data acquisition system. Theinfrastructure and detectors of the spectrometer as well as the performancecharacteristics and the analysis techniques applied to the experimental dataare described.

CMB-S4 Science Book, First Edition

  This book lays out the scientific goals to be addressed by thenext-generation ground-based cosmic microwave background experiment, CMB-S4,envisioned to consist of dedicated telescopes at the South Pole, the highChilean Atacama plateau and possibly a northern hemisphere site, all equippedwith new superconducting cameras. CMB-S4 will dramatically advance cosmologicalstudies by crossing critical thresholds in the search for the B-modepolarization signature of primordial gravitational waves, in the determinationof the number and masses of the neutrinos, in the search for evidence of newlight relics, in constraining the nature of dark energy, and in testing generalrelativity on large scales.

Observing the Evolution of the Universe

  How did the universe evolve? The fine angular scale (l>1000) temperature andpolarization anisotropies in the CMB are a Rosetta stone for understanding theevolution of the universe. Through detailed measurements one may addresseverything from the physics of the birth of the universe to the history of starformation and the process by which galaxies formed. One may in addition trackthe evolution of the dark energy and discover the net neutrino mass.  We are at the dawn of a new era in which hundreds of square degrees of skycan be mapped with arcminute resolution and sensitivities measured inmicroKelvin. Acquiring these data requires the use of special purposetelescopes such as the Atacama Cosmology Telescope (ACT), located in Chile, andthe South Pole Telescope (SPT). These new telescopes are outfitted with a newgeneration of custom mm-wave kilo-pixel arrays. Additional instruments are inthe planning stages.

Precise measurement of the top quark mass in the dilepton channel at D0

  We measure the top quark mass (mt) in ppbar collisions at a center of massenergy of 1.96 TeV using dilepton ttbar->W+bW-bbar->l+nubl-nubarbbar events,where l denotes an electron, a muon, or a tau that decays leptonically. Thedata correspond to an integrated luminosity of 5.4 fb-1 collected with the D0detector at the Fermilab Tevatron Collider. We obtain mt = 174.0 +- 1.8(stat)+- 2.4(syst) GeV, which is in agreement with the current world average mt =173.3 +- 1.1 GeV. This is currently the most precise measurement of mt in thedilepton channel.

Measurement of the W boson helicity in top quark decays using 5.4 fb^-1  of ppbar collision data

  We present a measurement of the helicity of the W boson produced in top quarkdecays using ttbar decays in the l+jets and dilepton final states selected froma sample of 5.4 fb^-1 of collisions recorded using the D0 detector at theFermilab Tevatron ppbar collider. We measure the fractions of longitudinal andright-handed W bosons to be f_0 = 0.669 +- 0.102 [ +- 0.078 (stat.) +- 0.065(syst.)] and f_+ = 0.023 +- 0.053 [+- 0.041 (stat.) +- 0.034 (syst.)],respectively. This result is consistent at the 98% level with the standardmodel. A measurement with f_0 fixed to the value from the standard model yieldsf_+ = 0.010 +- 0.037 [+- 0.022 (stat.) +- 0.030 (syst.) ].

Determination of the width of the top quark

  We extract the total width of the top quark, Gamma_t, from the partial decaywidth Gamma(t -> W b) measured using the t-channel cross section for single topquark production and from the branching fraction B(t -> W b) measured in ttbarevents using up to 2.3 fb^-1 of integrated luminosity collected by the D0Collaboration at the Tevatron ppbar Collider. The result is Gamma_t = 1.99+0.69 -0.55 GeV, which translates to a top-quark lifetime of tau_t = (3.3 +1.3-0.9) x 10^-25 s. Assuming a high mass fourth generation b' quark and unitarityof the four-generation quark-mixing matrix, we set the first upper limit on|Vtb'| < 0.63 at 95% C.L.

Search for pair production of the scalar top quark in the electron-muon  final state

  We report the result of a search for the pair production of the lightestsupersymmetric partner of the top quark ($\tilde{t}_1$) in $p\bar{p}$collisions at a center-of-mass energy of 1.96 TeV at the Fermilab Tevatroncollider corresponding to an integrated luminosity of 5.4 fb$^{-1}$. The scalartop quarks are assumed to decay into a $b$ quark, a charged lepton, and ascalar neutrino ($\tilde{\nu}$), and the search is performed in the electronplus muon final state. No significant excess of events above the standard modelprediction is detected, and improved exclusion limits at the 95% C.L. are setin the the ($M_{\tilde{t}_1}$,$M_{\tilde{\nu}}$) mass plane.

Measurement of the differential cross section dÏƒ/dt in elastic  $p\bar{p}$ scattering at sqrt(s)=1.96 TeV

  We present a measurement of the elastic differential cross section$d\sigma(p\bar{p}\rightarrow p\bar{p})/dt$ as a function of thefour-momentum-transfer squared t. The data sample corresponds to an integratedluminosity of $\approx 31 nb^{-1}$ collected with the D0 detector usingdedicated Tevatron $p\bar{p} $ Collider operating conditions at sqrt(s) = 1.96TeV and covers the range $0.26 <|t|< 1.2 GeV^2$. For $|t|<0.6 GeV^2$,d\sigma/dt is described by an exponential function of the form $Ae^{-b|t|}$with a slope parameter $ b = 16.86 \pm 0.10(stat) \pm 0.20(syst) GeV^{-2}$. Achange in slope is observed at $|t| \approx 0.6 GeV^2$, followed by a moregradual |t| dependence with increasing values of |t|.

Search for pair production of the scalar top quark in muon+tau final  states

  We present a search for the pair production of scalar top quarks($\tilde{t}_{1}$), the lightest supersymmetric partners of the top quarks, in$p\bar{p}$ collisions at a center-of-mass energy of 1.96 TeV, using datacorresponding to an integrated luminosity of {7.3 $fb^{-1}$} collected with the\dzero experiment at the Fermilab Tevatron Collider. Each scalar top quark isassumed to decay into a $b$ quark, a charged lepton, and a scalar neutrino($\tilde{\nu}$). We investigate final states arising from $\tilde{t}_{1}\bar{\tilde{t}_{1}} \rightarrow b\bar{b}\mu\tau \tilde{\nu} \tilde{\nu}$ and$\tilde{t}_{1} \bar{\tilde{t}_{1}} \rightarrow b\bar{b}\tau\tau \tilde{\nu}\tilde{\nu}$. With no significant excess of events observed above thebackground expected from the standard model, we set exclusion limits on thisproduction process in the ($m_{\tilde{t}_{1}}$,$m_{\tilde{\nu}}$) plane.

