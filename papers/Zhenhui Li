Holographic Dark Energy with Cosmological Constant

  Inspired by the multiverse scenario, we study a heterotic dark energy modelin which there are two parts, the first being the cosmological constant and thesecond being the holographic dark energy, thus this model is named the$\Lambda$HDE model. By studying the $\Lambda$HDE model theoretically, we findthat the parameters $d$ and $\Omega_{hde}$ are divided into a few domains inwhich the fate of the universe is quite different. We investigate dynamicalbehaviors of this model, and especially the future evolution of the universe.We perform fitting analysis on the cosmological parameters in the $\Lambda$HDEmodel by using the recent observational data. We find the model yields$\chi^2_{\rm min}=426.27$ when constrained by $\rm Planck+SNLS3+BAO+HST$,comparable to the results of the HDE model (428.20) and the concordant$\Lambda$CDM model (431.35). At 68.3\% CL, we obtain$-0.07<\Omega_{\Lambda0}<0.68$ and correspondingly $0.04<\Omega_{hde0}<0.79$,implying at present there is considerable degeneracy between the holographicdark energy and cosmological constant components in the $\Lambda$HDE model.

Cosmological constraints on the new holographic dark energy model with  action principle

  Recently, a New HDE model with action principle was proposed (Li and Miao,arXiv:1210.0966). This model completely solves the causality and circularproblems in the original HDE model, and is similar to the original model excepta new term that can be interpreted as dark radiation. In this paper, we makefurther investigations on this model from the aspect of cosmologicalobservations. Numerically, we confirm that the equations of motion force the$L(z=-1)=0$, making the cut-off $aL$ exactly the future event horizon. We alsoperform detailed analysis on the dynamical properties of the model, dividedinto the $c<6$ and $c\geq6$ cases ($c$ is a dimensionless parameter whichshould be decided by the data). From a combination of the presentUnion2.1+BAO+CMB+$H_0$ data, we find the model yields $\chi^2_{\rmmin}=548.798$ (in a non-flat Universe), comparable to the results of theoriginal HDE model (549.461) and the concordant $\Lambda$CDM model (550.354).At 95.4% CL, we get $1.41<c<3.09$ and correspondingly $-2.25<w(z=-1)<-1.39$,implying the Big Rip fate of the Universe at a high confidence level. Besides,for the constraints on dark radiation, we also get a rough estimation $N_{\rm\rm eff}=3.54^{+0.32+0.67}_{\rm -0.45-0.76}$, with the central value slightlylarger than the standard value 3.046.

Investigating the Possibility of a Turning Point in the Dark Energy  Equation of State

  We investigate a second order $parabolic$ parametrization,$w(a)=w_t+w_a(a_t-a)^2$, which is a direct characterization of a possible$turning$ in $w$. The cosmological consequence of this parametrization isexplored by using the observational data of the SNLS3 type Ia supernovaesample, the CMB measurements from WMAP9 and Planck, the Hubble parametermeasurement from HST, and the baryon acoustic oscillation (BAO) measurementsfrom 6dFGS, BOSS DR11 and improved WiggleZ. We found the existence of a turningpoint in $w$ at $a\sim0.7$ is favored at 1$\sigma$ CL. In the epoch $0.55< a<0.9$, $w<-1$ is favored at 1$\sigma$ CL, and this significance increases near$a=0.8$, reaching a 2$\sigma$ CL. The parabolic parametrization achieveequivalent performance to the $\Lambda$CDM and Chevallier-Polarski-Linder (CPL)models when the Akaike information criterion was used to assess them. Ouranalysis shows the value of considering high order parametrizations whenstudying the cosmological constraints on $w$.

Semantic Exploration of Traffic Dynamics

  Given a large collection of urban datasets, how can we find their hiddencorrelations? For example, New York City (NYC) provides open access to taxidata from year 2012 to 2015 with about half million taxi trips generated perday. In the meantime, we have a rich set of urban data in NYC includingpoints-of-interest (POIs), geo-tagged tweets, weather, vehicle collisions, etc.Is it possible that these ubiquitous datasets can be used to explain the citytraffic? Understanding the hidden correlation between external data and trafficdata would allow us to answer many important questions in urban computing suchas: If we observe a high traffic volume at Madison Square Garden (MSG) in NYC,is it because of the regular peak hour or a big event being held at MSG? If adisaster weather such as a hurricane or a snow storm hits the city, how wouldthe traffic be affected?  While existing studies may utilize external datasets for prediction task,they do not explicitly seek for direct explanations from the external datasets.In this paper, we present our results in attempts to understand taxi trafficdynamics in NYC from multiple external data sources. We use four real-worldubiquitous urban datasets, including POI, weather, geo-tagged tweet, andcollision records. To address the heterogeneity of ubiquitous urban data, wepresent carefully-designed feature representations for various datasets.Extensive experiments on real data demonstrate the explanatory power on taxitraffic by using external datasets. More specifically, our analysis suggeststhat POIs can well describe the regular traffic patterns. At the same time,geo-tagged tweets can explain irregular traffic caused by big events andweather can explain the abnormal traffic drop.

Revisit of the Interaction between Holographic Dark Energy and Dark  Matter

  In this paper we investigate the possible direct, non-gravitationalinteraction between holographic dark energy (HDE) and dark matter. Firstly, westart with two simple models with the interaction terms $Q \propto \rho_{dm}$and $Q \propto \rho_{de}$, and then we move on to the general form $Q \propto\rho_m^\alpha\rho_{de}^\beta$. The cosmological constraints of the models areobtained from the joint analysis of the present Union2.1+BAO+CMB+$H_0$ data. Wefind that the data slightly favor an energy flow from dark matter to darkenergy, although the original HDE model still lies in the 95.4% confidencelevel (CL) region. For all models we find $c<1$ at the 95.4% CL. We show thatcompared with the cosmic expansion, the effect of interaction on the evolutionof $\rho_{dm}$ and $\rho_{de}$ is smaller, and the relative increment(decrement) amount of the energy in the dark matter component is constrained tobe less than 9% (15%) at the 95.4% CL. By introducing the interaction, we findthat even when $c<1$ the big rip still can be avoided due to the existence of ade Sitter solution at $z\rightarrow-1$. We show that this solution can not beaccomplished in the two simple models, while for the general model such asolution can be achieved with a large $\beta$, and the big rip may be avoidedat the 95.4% CL.

Generalized Fisher Score for Feature Selection

  Fisher score is one of the most widely used supervised feature selectionmethods. However, it selects each feature independently according to theirscores under the Fisher criterion, which leads to a suboptimal subset offeatures. In this paper, we present a generalized Fisher score to jointlyselect features. It aims at finding an subset of features, which maximize thelower bound of traditional Fisher score. The resulting feature selectionproblem is a mixed integer programming, which can be reformulated as aquadratically constrained linear programming (QCLP). It is solved by cuttingplane algorithm, in each iteration of which a multiple kernel learning problemis solved alternatively by multivariate ridge regression and projected gradientdescent. Experiments on benchmark data sets indicate that the proposed methodoutperforms Fisher score as well as many other state-of-the-art featureselection methods.

Single-Carrier Modulation for Large-Scale Antenna Systems

  Large-scale antenna (LSA) has gained a lot of attention due to its greatpotential to significantly improve system throughput. In most existing works onLSA systems, orthogonal frequency division multiplexing (OFDM) is presumed todeal with frequency selectivity of wireless channels. Although LSA-OFDM is anatural evolution from multiple-input multiple-output OFDM (MIMO-OFDM), thedrawbacks of LSA-OFDM are inevitable, especially when used for the uplink. Inthis paper, we investigate single-carrier (SC) modulation for the uplinktransmission in LSA systems based on a novel waveform recovery theory, wherethe receiver is designed to recover the transmit waveform while theinformation-bearing symbols can be recovered by directly sampling the recoveredwaveform. The waveform recovery adopts the assumption that the antenna numberis infinite and the channels at different antennas are independent. Inpractical environments, however, the antenna number is always finite and thechannels at different antennas are also correlated when placing hundreds ofantennas in a small area. Therefore, we will also analyze the impacts of suchnon-ideal environments.

A Simple Baseline for Travel Time Estimation using Large-Scale Trip Data

  The increased availability of large-scale trajectory data around the worldprovides rich information for the study of urban dynamics. For example, NewYork City Taxi Limousine Commission regularly releases source-destinationinformation about trips in the taxis they regulate. Taxi data provideinformation about traffic patterns, and thus enable the study of urban flow --what will traffic between two locations look like at a certain date and time inthe future? Existing big data methods try to outdo each other in terms ofcomplexity and algorithmic sophistication. In the spirit of "big data beatsalgorithms", we present a very simple baseline which outperformsstate-of-the-art approaches, including Bing Maps and Baidu Maps (whose APIspermit large scale experimentation). Such a travel time estimation baseline hasseveral important uses, such as navigation (fast travel time estimates canserve as approximate heuristics for A search variants for path finding) andtrip planning (which uses operating hours for popular destinations along withtravel time estimates to create an itinerary).

Detecting Outliers in Data with Correlated Measures

  Advances in sensor technology have enabled the collection of large-scaledatasets. Such datasets can be extremely noisy and often contain a significantamount of outliers that result from sensor malfunction or human operationfaults. In order to utilize such data for real-world applications, it iscritical to detect outliers so that models built from these datasets will notbe skewed by outliers.  In this paper, we propose a new outlier detection method that utilizes thecorrelations in the data (e.g., taxi trip distance vs. trip time). Differentfrom existing outlier detection methods, we build a robust regression modelthat explicitly models the outliers and detects outliers simultaneously withthe model fitting.  We validate our approach on real-world datasets against methods specificallydesigned for each dataset as well as the state of the art outlier detectors.Our outlier detection method achieves better performances, demonstrating therobustness and generality of our method. Last, we report interesting casestudies on some outliers that result from atypical events.

Generalized Holographic Dark Energy and its Observational Constraints

  In the original holographic dark energy (HDE) model, the dark energy densityis proposed to be $\rho_{de} = 3c^2M^2_{pl}L^{-2}$, with $c$ is a dimensionlessconstant characterizing the properties of the HDE. In this work, we propose thegeneralized holographic dark energy (GHDE) model by considering the parameter$c$ as a redshift-dependent function $c(z)$. We derive all the physicalquantities of the GHDE model analytically, and fit the $c(z)$ by trying fourkinds of parametrizations. The cosmological constraints of the $c(z)$ areobtained from the joint analysis of the present SNLS3+BAO+CMB+$H_0$ data. Wefind that, compared with the original HDE model, the GHDE models can provide abetter fit to the data. For example, the GHDE model with JBP-type $c(z)$ canreduce the $\chi^2_{min}$ of the HDE model by 2.16. We also find that, unlikethe original HDE model with a phantom-like behavior in the future, the GHDEmodels can present many more different possibilities, i.e., it allows the GHDEin the future to be either quintessence like, cosmological constant like, orphantom like, depending on the forms of $c(z)$.

Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for  Traffic Prediction

  Traffic prediction has drawn increasing attention in AI research field due tothe increasing availability of large-scale traffic data and its importance inthe real world. For example, an accurate taxi demand prediction can assist taxicompanies in pre-allocating taxis. The key challenge of traffic prediction liesin how to model the complex spatial dependencies and temporal dynamics.Although both factors have been considered in modeling, existing works makestrong assumptions about spatial dependence and temporal dynamics, i.e.,spatial dependence is stationary in time, and temporal dynamics is strictlyperiodical. However, in practice, the spatial dependence could be dynamic(i.e., changing from time to time), and the temporal dynamics could have someperturbation from one period to another period. In this paper, we make twoimportant observations: (1) the spatial dependencies between locations aredynamic; and (2) the temporal dependency follows daily and weekly pattern butit is not strictly periodic for its dynamic temporal shifting. To address thesetwo issues, we propose a novel Spatial-Temporal Dynamic Network (STDN), inwhich a flow gating mechanism is introduced to learn the dynamic similaritybetween locations, and a periodically shifted attention mechanism is designedto handle long-term periodic temporal shifting. To the best of our knowledge,this is the first work that tackles both issues in a unified framework. Ourexperimental results on real-world traffic datasets verify the effectiveness ofthe proposed method.

Test $Î›$CDM model with High Redshift data from Baryon Acoustic  Oscillations

  The Baryon Acoustic Oscillations (BAO) provide a standard ruler for studyingcosmic expansion. The recent observations of BAO in SDSS DR9 and DR11 takemeasurements of $H(z)$ at several different redshifts. It is argued that thebehavior of dark energy could be constrained more effectively by addinghigh-redshift Hubble parameter data, such as the SDSS DR11 measurement of $H(z)= 222\pm7$ km/sec/Mpc at z = 2.34. In this paper, we investigate thesignificance of these BAO data in the flat $\Lambda$CDM model, by combiningthem with the recent observational data of the Hubble constant from localdistance ladder and the Cosmic Microwave Background (CMB) measurements fromPlanck+WP. We perform a detailed data analysis on these datasets and find thatthe recent observations of BAO in SDSS DR9 and DR11 have considerable tensionwith the Planck + WP measurements in the framework of the standard $\Lambda$CDMmodel. The fitting results show that the main contribution to the tension comesfrom the Hubble parameter measurement at redshift of $z=2.34$. But there is novisible tension once the joint data analysis by combining the datasets of SDSSand Planck+WP is performed. Thus in order to see whether dark energy doesevolve, we need more independent measurements of the Hubble parameter at highredshifts.

Learning from Multiple Cities: A Meta-Learning Approach for  Spatial-Temporal Prediction

  Spatial-temporal prediction is a fundamental problem for constructing smartcity, which is useful for tasks such as traffic control, taxi dispatching, andenvironmental policy making. Due to data collection mechanism, it is common tosee data collection with unbalanced spatial distributions. For example, somecities may release taxi data for multiple years while others only release a fewdays of data; some regions may have constant water quality data monitored bysensors whereas some regions only have a small collection of water samples. Inthis paper, we tackle the problem of spatial-temporal prediction for the citieswith only a short period of data collection. We aim to utilize the long-perioddata from other cities via transfer learning. Different from previous studiesthat transfer knowledge from one single source city to a target city, we arethe first to leverage information from multiple cities to increase thestability of transfer. Specifically, our proposed model is designed as aspatial-temporal network with a meta-learning paradigm. The meta-learningparadigm learns a well-generalized initialization of the spatial-temporalnetwork, which can be effectively adapted to target cities. In addition, apattern-based spatial-temporal memory is designed to distill long-term temporalinformation (i.e., periodicity). We conduct extensive experiments on two tasks:traffic (taxi and bike) prediction and water quality prediction. Theexperiments demonstrate the effectiveness of our proposed model over severalcompetitive baseline models.

Planck Constraints on Holographic Dark Energy

  We perform a detailed investigation on the cosmological constraints on theholographic dark energy (HDE) model by using the Planck data. HDE can provide agood fit to Planck high-l (l>40) temperature power spectrum, while thediscrepancy at l=20-40 found in LCDM remains unsolved in HDE. The Planck dataalone can lead to strong and reliable constraint on the HDE parameter c. At 68%CL, we get c=0.508+-0.207 with Planck+WP+lensing, favoring the present phantomHDE at > 2sigma CL. Comparably, by using WMAP9 alone we cannot get interestingconstraint on c. By combining Planck+WP with the BAO measurements from6dFGS+SDSS DR7(R)+BOSS DR9, the H0 measurement from HST, the SNLS3 and Union2.1SNIa data sets, we get 68% CL constraints c=0.484+-0.070, 0.474+-0.049,0.594+-0.051 and 0.642+-0.066. Constraints can be improved by 2%-15% if wefurther add the Planck lensing data. Compared with the WMAP9 results, thePlanck results reduce the error by 30%-60%, and prefer a phantom-like HDE athigher CL. We find no evident tension between Planck and BAO/HST. Especially,the strong correlation between Omegam h^3 and dark energy parameters is helpfulin relieving the tension between Planck and HST. The residualchi^2_{Planck+WP+HST}-chi^2_{Planck+WP} is 7.8 in LCDM, and is reduced to 1.0or 0.3 if we switch dark energy to the w model or the holographic model. Wefind SNLS3 is in tension with all other data sets; for Planck+WP, WMAP9 andBAO+HST, the corresponding Delta chi^2 is 6.4, 3.5 and 4.1, respectively.Comparably, Union2.1 is consistent with these data sets, but the combinationUnion2.1+BAO+HST is in tension with Planck+WP+lensing, corresponding to a Deltachi^2 8.6 (1.4% probability). Thus, it is not reasonable to perform anall-combined (CMB+SNIa+BAO+HST) analysis for HDE when using the Planck data.Our tightest self-consistent constraint is c=0.495+-0.039 obtained fromPlanck+WP+BAO+HST+lensing.

Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction

  Taxi demand prediction is an important building block to enabling intelligenttransportation systems in a smart city. An accurate prediction model can helpthe city pre-allocate resources to meet travel demand and to reduce empty taxison streets which waste energy and worsen the traffic congestion. With theincreasing popularity of taxi requesting services such as Uber and Didi Chuxing(in China), we are able to collect large-scale taxi demand data continuously.How to utilize such big data to improve the demand prediction is an interestingand critical real-world problem. Traditional demand prediction methods mostlyrely on time series forecasting techniques, which fail to model the complexnon-linear spatial and temporal relations. Recent advances in deep learninghave shown superior performance on traditionally challenging tasks such asimage classification by learning the complex features and correlations fromlarge-scale data. This breakthrough has inspired researchers to explore deeplearning techniques on traffic prediction problems. However, existing methodson traffic prediction have only considered spatial relation (e.g., using CNN)or temporal relation (e.g., using LSTM) independently. We propose a DeepMulti-View Spatial-Temporal Network (DMVST-Net) framework to model both spatialand temporal relations. Specifically, our proposed model consists of threeviews: temporal view (modeling correlations between future demand values withnear time points via LSTM), spatial view (modeling local spatial correlationvia local CNN), and semantic view (modeling correlations among regions sharingsimilar temporal patterns). Experiments on large-scale real taxi demand datademonstrate effectiveness of our approach over state-of-the-art methods.

