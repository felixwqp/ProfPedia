Knowledge Combination in Graphical Multiagent Model

  A graphical multiagent model (GMM) represents a joint distribution over the
behavior of a set of agents. One source of knowledge about agents' behavior may
come from gametheoretic analysis, as captured by several graphical game
representations developed in recent years. GMMs generalize this approach to
express arbitrary distributions, based on game descriptions or other sources of
knowledge bearing on beliefs about agent behavior. To illustrate the
flexibility of GMMs, we exhibit game-derived models that allow probabilistic
deviation from equilibrium, as well as models based on heuristic action choice.
We investigate three different methods of integrating these models into a
single model representing the combined knowledge sources. To evaluate the
predictive performance of the combined model, we treat as actual outcome the
behavior produced by a reinforcement learning process. We find that combining
the two knowledge sources, using any of the methods, provides better
predictions than either source alone. Among the combination methods, mixing
data outperforms the opinion pool and direct update methods investigated in
this empirical trial.


