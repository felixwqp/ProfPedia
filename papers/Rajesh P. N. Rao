Towards Neural Co-Processors for the Brain: Combining Decoding and  Encoding in Brain-Computer Interfaces

  The field of brain-computer interfaces is poised to advance from thetraditional goal of controlling prosthetic devices using brain signals tocombining neural decoding and encoding within a single neuroprosthetic device.Such a device acts as a "co-processor" for the brain, with applications rangingfrom inducing Hebbian plasticity for rehabilitation after brain injury toreanimating paralyzed limbs and enhancing memory. We review recent progress insimultaneous decoding and encoding for closed-loop control and plasticityinduction. To address the challenge of multi-channel decoding and encoding, weintroduce a unifying framework for developing brain co-processors based onartificial neural networks and deep learning. These "neural co-processors" canbe used to jointly optimize cost functions with the nervous system to achievedesired behaviors ranging from targeted neuro-rehabilitation to augmentation ofbrain function.

The Indus Script and Economics. A Role for Indus Seals and Tablets in  Rationing and Administration of Labor

  The Indus script remains one of the last major undeciphered scripts of theancient world. We focus here on Indus inscriptions on a group of miniaturetablets discovered by Meadow and Kenoyer in Harappa in 1997. By drawingparallels with proto-Elamite and proto-Cuneiform inscriptions, we explore howthese miniature tablets may have been used to record rations allocated toporters or laborers. We then show that similar inscriptions are found on stampseals, leading to the potentially provocative conclusion that rather thansimply indicating ownership of property, Indus seals may have been used forgenerating tokens, tablets and sealings for repetitive economic transactionssuch as rations and exchange of canonical amounts of goods, grains, animals,and labor in a barter-based economy.

Large Margin Boltzmann Machines and Large Margin Sigmoid Belief Networks

  Current statistical models for structured prediction make simplifyingassumptions about the underlying output graph structure, such as assuming alow-order Markov chain, because exact inference becomes intractable as thetree-width of the underlying graph increases. Approximate inference algorithms,on the other hand, force one to trade off representational power withcomputational efficiency. In this paper, we propose two new types ofprobabilistic graphical models, large margin Boltzmann machines (LMBMs) andlarge margin sigmoid belief networks (LMSBNs), for structured prediction.LMSBNs in particular allow a very fast inference algorithm for arbitrary graphstructures that runs in polynomial time with a high probability. Thisprobability is data-distribution dependent and is maximized in learning. Thenew approach overcomes the representation-efficiency trade-off in previousmodels and allows fast structured prediction with complicated graph structures.We present results from applying a fully connected model to multi-label sceneclassification and demonstrate that the proposed approach can yield significantperformance gains over current state-of-the-art methods.

Learning Deep Generative Spatial Models for Mobile Robots

  We propose a new probabilistic framework that allows mobile robots toautonomously learn deep, generative models of their environments that spanmultiple levels of abstraction. Unlike traditional approaches that combineengineered models for low-level features, geometry, and semantics, our approachleverages recent advances in Sum-Product Networks (SPNs) and deep learning tolearn a single, universal model of the robot's spatial environment. Our modelis fully probabilistic and generative, and represents a joint distribution overspatial information ranging from low-level geometry to semanticinterpretations. Once learned, it is capable of solving a wide range of tasks:from semantic classification of places, uncertainty estimation, and noveltydetection, to generation of place appearances based on semantic information andprediction of missing data in partial observations. Experiments on laser-rangedata from a mobile robot show that the proposed universal model obtainsperformance superior to state-of-the-art models fine-tuned to one specifictask, such as Generative Adversarial Networks (GANs) or SVMs.

Electrocorticographic Dynamics Predict Visually Guided Motor Imagery of  Grasp Shaping

  Identification of intended movement type and movement phase of hand graspshaping are critical features for the control of volitional neuroprosthetics.We demonstrate that neural dynamics during visually-guided imagined graspshaping can encode intended movement. We apply Procrustes analysis and LASSOregression to achieve 72% accuracy (chance = 25%) in distinguishing betweenvisually-guided imagined grasp trajectories. Further, we can predict the stageof grasp shaping in the form of elapsed time from start of trial (R2=0.4). Ourapproach contributes to more accurate single-trial decoding of higher-levelmovement goals and the phase of grasping movements in individuals not trainedwith brain-computer interfaces. We also find that the overall time-varyingtrajectory structure of imagined movements tend to be consistent withinindividuals, and that transient trajectory deviations within trials return tothe task-dependent trajectory mean. These overall findings may contribute tothe further understanding of the cortical dynamics of human motor imagery.

Learning Graph-Structured Sum-Product Networks for Probabilistic  Semantic Maps

  We introduce Graph-Structured Sum-Product Networks (GraphSPNs), aprobabilistic approach to structured prediction for problems where dependenciesbetween latent variables are expressed in terms of arbitrary, dynamic graphs.While many approaches to structured prediction place strict constraints on theinteractions between inferred variables, many real-world problems can be onlycharacterized using complex graph structures of varying size, oftencontaminated with noise when obtained from real data. Here, we focus on onesuch problem in the domain of robotics. We demonstrate how GraphSPNs can beused to bolster inference about semantic, conceptual place descriptions usingnoisy topological relations discovered by a robot exploring large-scale officespaces. Through experiments, we show that GraphSPNs consistently outperform thetraditional approach based on undirected graphical models, successfullydisambiguating information in global semantic maps built from uncertain, noisylocal evidence. We further exploit the probabilistic nature of the model toinfer marginal distributions over semantic descriptions of as yet unexploredplaces and detect spatial environment configurations that are novel andincongruent with the known evidence.

Transformational Sparse Coding

  A fundamental problem faced by object recognition systems is that objects andtheir features can appear in different locations, scales and orientations.Current deep learning methods attempt to achieve invariance to localtranslations via pooling, discarding the locations of features in the process.Other approaches explicitly learn transformed versions of the same feature,leading to representations that quickly explode in size. Instead of discardingthe rich and useful information about feature transformations to achieveinvariance, we argue that models should learn object features conjointly withtheir transformations to achieve equivariance. We propose a new model ofunsupervised learning based on sparse coding that can learn object featuresjointly with their affine transformations directly from images. Results basedon learning from natural images indicate that our approach matches thereconstruction quality of traditional sparse coding but with significantlyfewer degrees of freedom while simultaneously learning transformations fromdata. These results open the door to scaling up unsupervised learning to allowdeep feature+transformation learning in a manner consistent with theventral+dorsal stream architecture of the primate visual cortex.

Statistical analysis of the Indus script using $n$-grams

  The Indus script is one of the major undeciphered scripts of the ancientworld. The small size of the corpus, the absence of bilingual texts, and thelack of definite knowledge of the underlying language has frustrated efforts atdecipherment since the discovery of the remains of the Indus civilisation.Recently, some researchers have questioned the premise that the Indus scriptencodes spoken language. Building on previous statistical approaches, we applythe tools of statistical language processing, specifically $n$-gram Markovchains, to analyse the Indus script for syntax. Our main results are that thescript has well-defined signs which begin and end texts, that there isdirectionality and strong correlations in the sign order, and that there aregroups of signs which appear to have identical syntactic function. All theserequire no {\it a priori} suppositions regarding the syntactic or semanticcontent of the signs, but follow directly from the statistical analysis. Usinginformation theoretic measures, we find the information in the script to beintermediate between that of a completely random and a completely fixedordering of signs. Our study reveals that the Indus script is a structured signsystem showing features of a formal language, but, at present, cannotconclusively establish that it encodes {\it natural} language. Our $n$-gramMarkov model is useful for predicting signs which are missing or illegible in acorpus of Indus texts. This work forms the basis for the development of astochastic grammar which can be used to explore the syntax of the Indus scriptin greater detail.

Multistep Model for Predicting Upper-Limb 3D Isometric Force Application  from Pre-Movement Electrocorticographic Features

  Neural correlates of movement planning onset and direction may be present inhuman electrocorticography in the signal dynamics of both motor and non-motorcortical regions. We use a three-stage model of jPCA reduced-rank hidden Markovmodel (jPCA-RR-HMM), regularized shrunken-centroid discriminant analysis (RDA),and LASSO regression to extract direction-sensitive planning information andmovement onset in an upper-limb 3D isometric force task in a human subject.This mode achieves a relatively high true positive force-onset prediction rateof 60% within 250ms, and an above-chance 36% accuracy (17% chance) inpredicting one of six planned 3D directions of isometric force usingpre-movement signals. We also find direction-distinguishing information up to400ms before force onset in the pre-movement signals, captured by electrodesplaced over the limb-ipsilateral dorsal premotor regions. This approach cancontribute to more accurate decoding of higher-level movement goals, at earliertimescales, and inform sensor placement. Our results also contribute to furtherunderstanding of the spatiotemporal features of human motor planning.

Unsupervised decoding of long-term, naturalistic human neural recordings  with automated video and audio annotations

  Fully automated decoding of human activities and intentions from directneural recordings is a tantalizing challenge in brain-computer interfacing.Most ongoing efforts have focused on training decoders on specific, stereotypedtasks in laboratory settings. Implementing brain-computer interfaces (BCIs) innatural settings requires adaptive strategies and scalable algorithms thatrequire minimal supervision. Here we propose an unsupervised approach todecoding neural states from human brain recordings acquired in a naturalisticcontext. We demonstrate our approach on continuous long-termelectrocorticographic (ECoG) data recorded over many days from the brainsurface of subjects in a hospital room, with simultaneous audio and videorecordings. We first discovered clusters in high-dimensional ECoG recordingsand then annotated coherent clusters using speech and movement labels extractedautomatically from audio and video recordings. To our knowledge, thisrepresents the first time techniques from computer vision and speech processinghave been used for natural ECoG decoding. Our results show that ourunsupervised approach can discover distinct behaviors from ECoG data, includingmoving, speaking and resting. We verify the accuracy of our approach bycomparing to manual annotations. Projecting the discovered cluster centers backonto the brain, this technique opens the door to automated functional brainmapping in natural settings.

Interactive Web Application for Exploring Matrices of Neural  Connectivity

  We present here a browser-based application for visualizing patterns ofconnectivity in 3D stacked data matrices with large numbers of pairwiserelations. Visualizing a connectivity matrix, looking for trends and patterns,and dynamically manipulating these values is a challenge for scientists fromdiverse fields, including neuroscience and genomics. In particular,high-dimensional neural data include those acquired via electroencephalography(EEG), electrocorticography (ECoG), magnetoencephalography (MEG), andfunctional MRI. Neural connectivity data contains multivariate attributes foreach edge between different brain regions, which motivated our lightweight,open source, easy-to-use visualization tool for the exploration of theseconnectivity matrices to highlight connections of interest. Here we present aclient-side, mobile-compatible visualization tool written entirely inHTML5/JavaScript that allows in-browser manipulation of user-defined files forexploration of brain connectivity. Visualizations can highlight differentaspects of the data simultaneously across different dimensions. Input files arein JSON format, and custom Python scripts have been written to parse MATLAB orPython data files into JSON-loadable format. We demonstrate the analysis ofconnectivity data acquired via human ECoG recordings as a domain-specificimplementation of our application. We envision applications for thisinteractive tool in fields seeking to visualize pairwise connectivity.

BrainNet: A Multi-Person Brain-to-Brain Interface for Direct  Collaboration Between Brains

  We present BrainNet which, to our knowledge, is the first multi-personnon-invasive direct brain-to-brain interface for collaborative problem solving.The interface combines electroencephalography (EEG) to record brain signals andtranscranial magnetic stimulation (TMS) to deliver information noninvasively tothe brain. The interface allows three human subjects to collaborate and solve atask using direct brain-to-brain communication. Two of the three subjects are"Senders" whose brain signals are decoded using real-time EEG data analysis toextract decisions about whether to rotate a block in a Tetris-like game beforeit is dropped to fill a line. The Senders' decisions are transmitted via theInternet to the brain of a third subject, the "Receiver," who cannot see thegame screen. The decisions are delivered to the Receiver's brain via magneticstimulation of the occipital cortex. The Receiver integrates the informationreceived and makes a decision using an EEG interface about either turning theblock or keeping it in the same position. A second round of the game gives theSenders one more chance to validate and provide feedback to the Receiver'saction. We evaluated the performance of BrainNet in terms of (1) Group-levelperformance during the game; (2) True/False positive rates of subjects'decisions; (3) Mutual information between subjects. Five groups of threesubjects successfully used BrainNet to perform the Tetris task, with an averageaccuracy of 0.813. Furthermore, by varying the information reliability of theSenders by artificially injecting noise into one Sender's signal, we found thatReceivers are able to learn which Sender is more reliable based solely on theinformation transmitted to their brains. Our results raise the possibility offuture brain-to-brain interfaces that enable cooperative problem solving byhumans using a "social network" of connected brains.

