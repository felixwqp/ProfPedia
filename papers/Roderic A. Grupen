Intrinsically Motivated Multimodal Structure Learning

  We present a long-term intrinsically motivated structure learning method for
modeling transition dynamics during controlled interactions between a robot and
semi-permanent structures in the world. In particular, we discuss how
partially-observable state is represented using distributions over a Markovian
state and build models of objects that predict how state distributions change
in response to interactions with such objects. These structures serve as the
basis for a number of possible future tasks defined as Markov Decision
Processes (MDPs). The approach is an example of a structure learning technique
applied to a multimodal affordance representation that yields a population of
forward models for use in planning. We evaluate the approach using experiments
on a bimanual mobile manipulator (uBot-6) that show the performance of model
acquisition as the number of transition actions increases.


