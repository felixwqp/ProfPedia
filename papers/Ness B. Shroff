Node Weighted Scheduling

  This paper proposes a new class of online policies for scheduling in
input-buffered crossbar switches. Our policies are throughput optimal for a
large class of arrival processes which satisfy strong-law of large numbers.
Given an initial configuration and no further arrivals, our policies drain all
packets in the system in the minimal amount of time (providing an online
alternative to the batch approach based on Birkhoff-VonNeumann decompositions).
We show that it is possible for policies in our class to be throughput optimal
even if they are not constrained to be maximal in every time slot.
  Most algorithms for switch scheduling take an edge based approach; in
contrast, we focus on scheduling (a large enough set of) the most congested
ports. This alternate approach allows for lower-complexity algorithms, and also
requires a non-standard technique to prove throughput-optimality. One algorithm
in our class, Maximum Vertex-weighted Matching (MVM) has worst-case complexity
similar to Max-size Matching, and in simulations shows slightly better delay
performance than Max-(edge)weighted-Matching (MWM).


Maximizing System Throughput Using Cooperative Sensing in Multi-Channel
  Cognitive Radio Networks

  In Cognitive Radio Networks (CRNs), unlicensed users are allowed to access
the licensed spectrum when it is not currently being used by primary users
(PUs). In this paper, we study the throughput maximization problem for a
multi-channel CRN where each SU can only sense a limited number of channels. We
show that this problem is strongly NP-hard, and propose an approximation
algorithm with a factor at least $1/2\mu$ where $\mu \in [1,2]$ is a system
parameter reflecting the sensing capability of SUs across channels and their
sensing budgets. This performance guarantee is achieved by exploiting a nice
structural property of the objective function and constructing a particular
matching. Our numerical results demonstrate the advantage of our algorithm
compared with both a random and a greedy sensing assignment algorithm.


An Analytical Approach to the Adoption of Asymmetric Bidirectional
  Firewalls: Need for Regulation?

  Recent incidents of cybersecurity violations have revealed the importance of
having firewalls and other intrusion detection systems to monitor traffic
entering and leaving access networks. But the adoption of such security
measures is often stymied by `free-riding' effects and `shortsightedness' among
Internet service providers (ISPs). In this work, we develop an analytical
framework that not only accounts for these issues but also incorporates
technological factors, like asymmetries in the performance of bidirectional
firewalls. Results on the equilibrium adoption and stability are presented,
along with detailed analysis on several policy issues related to social
welfare, price of anarchy, and price of shortsightedness.


On the Generalized Delay-Capacity Tradeoff of Mobile Networks with
  Lévy Flight Mobility

  In the literature, scaling laws for wireless mobile networks have been
characterized under various models of node mobility and several assumptions on
how communication occurs between nodes. To improve the realism in the analysis
of scaling laws, we propose a new analytical framework. The framework is the
first to consider a L\'{e}vy flight mobility pattern, which is known to closely
mimic human mobility patterns. Also, this is the first work that allows nodes
to communicate while being mobile. Under this framework, delays ($\bar{D}$) to
obtain various levels of per-node throughput $(\lambda)$ for L\'evy flight are
suggested as $\bar{D}(\lambda) = O(\sqrt{\min (n^{1+\alpha} \lambda, n^2)})$,
where L\'evy flight is a random walk of a power-law flight distribution with an
exponent $\alpha \in (0,2]$. The same framework presents a new tighter tradeoff
$\bar{D}(\lambda) = O(\sqrt{\max (1,n\lambda^3)})$ for \textit{i.i.d.}
mobility, whose delays are lower than existing results for the same levels of
per-node throughput.


Throughput of Rateless Codes over Broadcast Erasure Channels

  In this paper, we characterize the throughput of a broadcast network with n
receivers using rateless codes with block size K. We assume that the underlying
channel is a Markov modulated erasure channel that is i.i.d. across users, but
can be correlated in time. We characterize the system throughput asymptotically
in n. Specifically, we explicitly show how the throughput behaves for different
values of the coding block size K as a function of n, as n approaches infinity.
For finite values of K and n, under the more restrictive assumption of
Gilbert-Elliott channels, we are able to provide a lower bound on the maximum
achievable throughput. Using simulations we show the tightness of the bound
with respect to system parameters n and K, and find that its performance is
significantly better than the previously known lower bounds.


Scheduling of Multicast and Unicast Services under Limited Feedback by
  using Rateless Codes

  Many opportunistic scheduling techniques are impractical because they require
accurate channel state information (CSI) at the transmitter. In this paper, we
investigate the scheduling of unicast and multicast services in a downlink
network with a very limited amount of feedback information. Specifically,
unicast users send imperfect (or no) CSI and infrequent acknowledgements (ACKs)
to a base station, and multicast users only report infrequent ACKs to avoid
feedback implosion. We consider the use of physical-layer rateless codes, which
not only combats channel uncertainty, but also reduces the overhead of ACK
feedback. A joint scheduling and power allocation scheme is developed to
realize multiuser diversity gain for unicast service and multicast gain for
multicast service. We prove that our scheme achieves a near-optimal throughput
region. Our simulation results show that our scheme significantly improves the
network throughput over schemes employing fixed-rate codes or using only
unicast communications.


Scheduling with Rate Adaptation under Incomplete Knowledge of
  Channel/Estimator Statistics

  In time-varying wireless networks, the states of the communication channels
are subject to random variations, and hence need to be estimated for efficient
rate adaptation and scheduling. The estimation mechanism possesses inaccuracies
that need to be tackled in a probabilistic framework. In this work, we study
scheduling with rate adaptation in single-hop queueing networks under two
levels of channel uncertainty: when the channel estimates are inaccurate but
complete knowledge of the channel/estimator joint statistics is available at
the scheduler; and when the knowledge of the joint statistics is incomplete. In
the former case, we characterize the network stability region and show that a
maximum-weight type scheduling policy is throughput-optimal. In the latter
case, we propose a joint channel statistics learning - scheduling policy. With
an associated trade-off in average packet delay and convergence time, the
proposed policy has a stability region arbitrarily close to the stability
region of the network under full knowledge of channel/estimator joint
statistics.


Low-complexity Optimal Scheduling over Correlated Fading Channels with
  ARQ Feedback

  We investigate the downlink scheduling problem under Markovian ON/OFF fading
channels, where the instantaneous channel state information is not directly
accessible, but is revealed via ARQ-type feedback. The scheduler can exploit
the temporal correlation/channel memory inherent in the Markovian channels to
improve network performance. However, designing low-complexity and
throughput-optimal algorithms under temporal correlation is a challenging
problem. In this paper, we find that under an average number of transmissions
constraint, a low-complexity index policy is throughput-optimal. The policy
uses Whittle's index value, which was previously used to capture opportunistic
scheduling under temporally correlated channels. Our results build on the
interesting finding that, under the intricate queue length and channel memory
evolutions, the importance of scheduling a user is captured by a simple
multiplication of its queue length and Whittle's index value. The proposed
queue-based index policy has provably low complexity. Numerical results show
that significant throughput gains can be realized by exploiting the channel
memory using the proposed low-complexity policy.


Optimal Energy-Aware Epidemic Routing in DTNs

  In this work, we investigate the use of epidemic routing in energy
constrained Delay Tolerant Networks (DTNs). In epidemic routing, messages are
relayed by intermediate nodes at contact opportunities, i.e., when pairs of
nodes come within the transmission range of each other. Each node needs to
decide whether to forward its message upon contact with a new node based on its
own residual energy level and the age of that message. We mathematically
characterize the fundamental trade-off between energy conservation and a
measure of Quality of Service as a dynamic energy-dependent optimal control
problem. We prove that in the mean-field regime, the optimal dynamic forwarding
decisions follow simple threshold-based structures in which the forwarding
threshold for each node depends on its current remaining energy. We then
characterize the nature of this dependence. Our simulations reveal that the
optimal dynamic policy significantly outperforms heuristics.


Secrecy Outage Capacity of Fading Channels

  This paper considers point to point secure communication over flat fading
channels under an outage constraint. More specifically, we extend the
definition of outage capacity to account for the secrecy constraint and obtain
sharp characterizations of the corresponding fundamental limits under two
different assumptions on the transmitter CSI (Channel state information).
First, we find the outage secrecy capacity assuming that the transmitter has
perfect knowledge of the legitimate and eavesdropper channel gains. In this
scenario, the capacity achieving scheme relies on opportunistically exchanging
private keys between the legitimate nodes. These keys are stored in a key
buffer and later used to secure delay sensitive data using the Vernam's one
time pad technique. We then extend our results to the more practical scenario
where the transmitter is assumed to know only the legitimate channel gain.
Here, our achievability arguments rely on privacy amplification techniques to
generate secret key bits. In the two cases, we also characterize the optimal
power control policies which, interestingly, turn out to be a judicious
combination of channel inversion and the optimal ergodic strategy. Finally, we
analyze the effect of key buffer overflow on the overall outage probability.


Graph-Theoretic Characterization of The Feasibility of The
  Precoding-Based 3-Unicast Interference Alignment Scheme

  A new precoding-based intersession network coding (NC) scheme has recently
been proposed, which applies the interference alignment technique, originally
devised for wireless interference channels, to the 3-unicast problem of
directed acyclic networks. The main result of this work is a graph-theoretic
characterization of the feasibility of the 3-unicast interference alignment
scheme. To that end, we first investigate several key relationships between the
point-to-point network channel gains and the underlying graph structure. Such
relationships turn out to be critical when characterizing graph-theoretically
the feasibility of precoding-based solutions.


Life-Add: Lifetime Adjustable Design for WiFi Networks with
  Heterogeneous Energy Supplies

  WiFi usage significantly reduces the battery lifetime of handheld devices
such as smartphones and tablets, due to its high energy consumption. In this
paper, we propose "Life-Add": a Lifetime Adjustable design for WiFi networks,
where the devices are powered by battery, electric power, and/or renewable
energy. In Life-Add, a device turns off its radio to save energy when the
channel is sensed to be busy, and sleeps for a random time period before
sensing the channel again. Life-Add carefully controls the devices' average
sleep periods to improve their throughput while satisfying their operation time
requirement. It is proven that Life-Add achieves near-optimal proportional-fair
utility performance for single access point (AP) scenarios. Moreover, Life-Add
alleviates the near-far effect and hidden terminal problem in general multiple
AP scenarios. Our ns-3 simulations show that Life-Add simultaneously improves
the lifetime, throughput, and fairness performance of WiFi networks, and
coexists harmoniously with IEEE 802.11.


Age-Optimal Information Updates in Multihop Networks

  The problem of reducing the age-of-information has been extensively studied
in the single-hop networks. In this paper, we minimize the age-of-information
in general multihop networks. If the packet transmission times over the network
links are exponentially distributed, we prove that a preemptive Last Generated
First Served (LGFS) policy results in smaller age processes at all nodes of the
network (in a stochastic ordering sense) than any other causal policy. In
addition, for arbitrary general distributions of packet transmission times, the
non-preemptive LGFS policy is shown to minimize the age processes at all nodes
of the network among all non-preemptive work-conserving policies (again in a
stochastic ordering sense). It is surprising that such simple policies can
achieve optimality of the joint distribution of the age processes at all nodes
even under arbitrary network topologies, as well as arbitrary packet generation
and arrival times. These optimality results not only hold for the age
processes, but also for any non-decreasing functional of the age processes.


Throughput-Delay Analysis of Random Linear Network Coding for Wireless
  Broadcasting

  In an unreliable single-hop broadcast network setting, we investigate the
throughput and decoding-delay performance of random linear network coding as a
function of the coding window size and the network size. Our model consists of
a source transmitting packets of a single flow to a set of $n$ users over
independent erasure channels. The source performs random linear network coding
(RLNC) over $k$ (coding window size) packets and broadcasts them to the users.
We note that the broadcast throughput of RLNC must vanish with increasing $n$,
for any fixed $k.$ Hence, in contrast to other works in the literature, we
investigate how the coding window size $k$ must scale for increasing $n$. Our
analysis reveals that the coding window size of $\Theta(\ln(n))$ represents a
phase transition rate, below which the throughput converges to zero, and above
which it converges to the broadcast capacity. Further, we characterize the
asymptotic distribution of decoding delay and provide approximate expressions
for the mean and variance of decoding delay for the scaling regime of
$k=\omega(\ln(n)).$ These asymptotic expressions reveal the impact of channel
correlations on the throughput and delay performance of RLNC. We also show how
our analysis can be extended to other rateless block coding schemes such as the
LT codes. Finally, we comment on the extension of our results to the cases of
dependent channels across users and asymmetric channel model.


Delay-Based Back-Pressure Scheduling in Multihop Wireless Networks

  Scheduling is a critical and challenging resource allocation mechanism for
multihop wireless networks. It is well known that scheduling schemes that favor
links with larger queue length can achieve high throughput performance.
However, these queue-length-based schemes could potentially suffer from large
(even infinite) packet delays due to the well-known last packet problem,
whereby packets belonging to some flows may be excessively delayed due to lack
of subsequent packet arrivals. Delay-based schemes have the potential to
resolve this last packet problem by scheduling the link based on the delay the
packet has encountered. However, characterizing throughput-optimality of these
delay-based schemes has largely been an open problem in multihop wireless
networks (except in limited cases where the traffic is single-hop.) In this
paper, we investigate delay-based scheduling schemes for multihop traffic
scenarios with fixed routes. We develop a scheduling scheme based on a new
delay metric, and show that the proposed scheme achieves optimal throughput
performance. Further, we conduct simulations to support our analytical results,
and show that the delay-based scheduler successfully removes excessive packet
delays, while it achieves the same throughput region as the queue-length-based
scheme.


Throughput-optimal Scheduling in Multi-hop Wireless Networks without
  Per-flow Information

  In this paper, we consider the problem of link scheduling in multi-hop
wireless networks under general interference constraints. Our goal is to design
scheduling schemes that do not use per-flow or per-destination information,
maintain a single data queue for each link, and exploit only local information,
while guaranteeing throughput optimality. Although the celebrated back-pressure
algorithm maximizes throughput, it requires per-flow or per-destination
information. It is usually difficult to obtain and maintain this type of
information, especially in large networks, where there are numerous flows.
Also, the back-pressure algorithm maintains a complex data structure at each
node, keeps exchanging queue length information among neighboring nodes, and
commonly results in poor delay performance. In this paper, we propose
scheduling schemes that can circumvent these drawbacks and guarantee throughput
optimality. These schemes use either the readily available hop-count
information or only the local information for each link. We rigorously analyze
the performance of the proposed schemes using fluid limit techniques via an
inductive argument and show that they are throughput-optimal. We also conduct
simulations to validate our theoretical results in various settings, and show
that the proposed schemes can substantially improve the delay performance in
most scenarios.


Optimal Distributed Resource Allocation for Decode-and-Forward Relay
  Networks

  This paper presents a distributed resource allocation algorithm to jointly
optimize the power allocation, channel allocation and relay selection for
decode-and-forward (DF) relay networks with a large number of sources, relays,
and destinations. The well-known dual decomposition technique cannot directly
be applied to resolve this problem, because the achievable data rate of DF
relaying is not strictly concave, and thus the local resource allocation
subproblem may have non-unique solutions. We resolve this non-strict concavity
problem by using the idea of the proximal point method, which adds quadratic
terms to make the objective function strictly concave. However, the proximal
solution adds an extra layer of iterations over typical duality based
approaches, which can significantly slow down the speed of convergence. To
address this key weakness, we devise a fast algorithm without the need for this
additional layer of iterations, which converges to the optimal solution. Our
algorithm only needs local information exchange, and can easily adapt to
variations of network size and topology. We prove that our distributed resource
allocation algorithm converges to the optimal solution. A channel resource
adjustment method is further developed to provide more channel resources to the
bottleneck links and realize traffic load balance. Numerical results are
provided to illustrate the benefits of our algorithm.


Delay Asymptotics with Retransmissions and Incremental Redundancy Codes
  over Erasure Channels

  Recent studies have shown that retransmissions can cause heavy-tailed
transmission delays even when packet sizes are light-tailed. Moreover, the
impact of heavy-tailed delays persists even when packets size are upper
bounded. The key question we study in this paper is how the use of coding
techniques to transmit information, together with different system
configurations, would affect the distribution of delay. To investigate this
problem, we model the underlying channel as a Markov modulated binary erasure
channel, where transmitted bits are either received successfully or erased.
Erasure codes are used to encode information prior to transmission, which
ensures that a fixed fraction of the bits in the codeword can lead to
successful decoding. We use incremental redundancy codes, where the codeword is
divided into codeword trunks and these trunks are transmitted one at a time to
provide incremental redundancies to the receiver until the information is
recovered. We characterize the distribution of delay under two different
scenarios: (I) Decoder uses memory to cache all previously successfully
received bits. (II) Decoder does not use memory, where received bits are
discarded if the corresponding information cannot be decoded. In both cases, we
consider codeword length with infinite and finite support. From a theoretical
perspective, our results provide a benchmark to quantify the tradeoff between
system complexity and the distribution of delay.


On the Efficiency-vs-Security Tradeoff in the Smart Grid

  The smart grid is envisioned to significantly enhance the efficiency of
energy consumption, by utilizing two-way communication channels between
consumers and operators. For example, operators can opportunistically leverage
the delay tolerance of energy demands in order to balance the energy load over
time, and hence, reduce the total operational cost. This opportunity, however,
comes with security threats, as the grid becomes more vulnerable to
cyber-attacks. In this paper, we study the impact of such malicious
cyber-attacks on the energy efficiency of the grid in a simplified setup. More
precisely, we consider a simple model where the energy demands of the smart
grid consumers are intercepted and altered by an active attacker before they
arrive at the operator, who is equipped with limited intrusion detection
capabilities. We formulate the resulting optimization problems faced by the
operator and the attacker and propose several scheduling and attack strategies
for both parties. Interestingly, our results show that, as opposed to
facilitating cost reduction in the smart grid, increasing the delay tolerance
of the energy demands potentially allows the attacker to force increased costs
on the system. This highlights the need for carefully constructed and robust
intrusion detection mechanisms at the operator.


Distributed Power Allocation for Coordinated Multipoint Transmissions in
  Distributed Antenna Systems

  This paper investigates the distributed power allocation problem for
coordinated multipoint (CoMP) transmissions in distributed antenna systems
(DAS). Traditional duality based optimization techniques cannot be directly
applied to this problem, because the non-strict concavity of the CoMP
transmission's achievable rate with respect to the transmission power induces
that the local power allocation subproblems have non-unique optimum solutions.
We propose a distributed power allocation algorithm to resolve this non-strict
concavity difficulty. This algorithm only requires local information exchange
among neighboring base stations serving the same user, and is thus scalable as
the network size grows. The step-size parameters of this algorithm are
determined by only local user access relationship (i.e., the number of users
served by each antenna), but do not rely on channel coefficients. Therefore,
the convergence speed of this algorithm is quite robust to different channel
fading coefficients. We rigorously prove that this algorithm converges to an
optimum solution of the power allocation problem. Simulation results are
presented to demonstrate the effectiveness of the proposed power allocation
algorithm.


Capacity of Compound MIMO Gaussian Channels with Additive Uncertainty

  This paper considers reliable communications over a multiple-input
multiple-output (MIMO) Gaussian channel, where the channel matrix is within a
bounded channel uncertainty region around a nominal channel matrix, i.e., an
instance of the compound MIMO Gaussian channel. We study the optimal transmit
covariance matrix design to achieve the capacity of compound MIMO Gaussian
channels, where the channel uncertainty region is characterized by the spectral
norm. This design problem is a challenging non-convex optimization problem.
However, in this paper, we reveal that this problem has a hidden convexity
property, which can be exploited to map the problem into a convex optimization
problem. We first prove that the optimal transmit design is to diagonalize the
nominal channel, and then show that the duality gap between the capacity of the
compound MIMO Gaussian channel and the min-max channel capacity is zero, which
proves the conjecture of Loyka and Charalambous (IEEE Trans. Inf. Theory, vol.
58, no. 4, pp. 2048-2063, 2012). The key tools for showing these results are a
new matrix determinant inequality and some unitarily invariant properties.


Distributed Cross-Layer Optimization in Wireless Networks: A
  Second-Order Approach

  Due to the rapidly growing scale and heterogeneity of wireless networks, the
design of distributed cross-layer optimization algorithms have received
significant interest from the networking research community. So far, the
standard distributed cross-layer approach in the literature is based on
first-order Lagrangian dual decomposition and the subgradient method, which
suffers a slow convergence rate. In this paper, we make the first known attempt
to develop a distributed Newton's method, which is second-order and enjoys a
quadratic convergence rate. However, due to interference in wireless networks,
the Hessian matrix of the cross-layer problem has an non-separable structure.
As a result, developing a distributed second-order algorithm is far more
challenging than its counterpart for wireline networks. Our main results in
this paper are two-fold: i) For a special network setting where all links
mutually interfere, we derive decentralized closed-form expressions to compute
the Hessian inverse; ii) For general wireless networks where the interference
relationships are arbitrary, we propose a distributed iterative matrix
splitting scheme for the Hessian inverse. These results successfully lead to a
new theoretical framework for cross-layer optimization in wireless networks.
More importantly, our work contributes to an exciting second-order paradigm
shift in wireless networks optimization theory.


Providing Probabilistic Guarantees on the Time of Information Spread in
  Opportunistic Networks

  A variety of mathematical tools have been developed for predicting the
spreading patterns in a number of varied environments including infectious
diseases, computer viruses, and urgent messages broadcast to mobile agent
(e.g., humans, vehicles, and mobile devices). These tools have mainly focused
on estimating the average time for the spread to reach a fraction (e.g.,
$\alpha$) of the agents, i.e., the so-called average completion time
$E(T_{\alpha})$. We claim that providing probabilistic guarantee on the time
for the spread $T_{\alpha}$ rather than only its average gives a much better
understanding of the spread, and hence could be used to design improved methods
to prevent epidemics or devise accelerated methods for distributing data. To
demonstrate the benefits, we introduce a new metric $G_{\alpha, \beta}$ that
denotes the time required to guarantee $\alpha$ completion with probability
$\beta$, and develop a new framework to characterize the distribution of
$T_\alpha$ for various spread parameters such as number of seeds, level of
contact rates, and heterogeneity in contact rates. We apply our technique to an
experimental mobility trace of taxies in Shanghai and show that our framework
enables us to allocate resources (i.e., to control spread parameters) for
acceleration of spread in a far more efficient way than the state-of-the-art.


Low-Complexity Scheduling Policies for Achieving Throughput and
  Asymptotic Delay Optimality in Multi-Channel Wireless Networks

  In this paper, we study the scheduling problem for downlink transmission in a
multi-channel (e.g., OFDM-based) wireless network. We focus on a single cell,
with the aim of developing a unifying framework for designing low-complexity
scheduling policies that can provide optimal performance in terms of both
throughput and delay. We develop new easy-to-verify sufficient conditions for
rate-function delay optimality (in the many-channel many-user asymptotic
regime) and throughput optimality (in general non-asymptotic setting),
respectively. The sufficient conditions allow us to prove rate-function delay
optimality for a class of Oldest Packets First (OPF) policies and throughput
optimality for a large class of Maximum Weight in the Fluid limit (MWF)
policies, respectively. By exploiting the special features of our carefully
chosen sufficient conditions and intelligently combining policies from the
classes of OPF and MWF policies, we design hybrid policies that are both
rate-function delay-optimal and throughput-optimal with a complexity of
$O(n^{2.5} \log n)$, where $n$ is the number of channels or users. Our
sufficient condition is also used to show that a previously proposed policy
called Delay Weighted Matching (DWM) is rate-function delay-optimal. However,
DWM incurs a high complexity of $O(n^5)$. Thus, our approach yields
significantly lower complexity than the only previously designed delay and
throughput optimal scheduling policy. We also conduct numerical experiments to
validate our theoretical results.


Network Control without CSI using Rateless Codes for Downlink Cellular
  Systems

  Wireless network scheduling and control techniques (e.g., opportunistic
scheduling) rely heavily on access to Channel State Information (CSI). However,
obtaining this information is costly in terms of bandwidth, time, and power,
and could result in large overhead. Therefore, a critical question is how to
optimally manage network resources in the absence of such information. To that
end, we develop a cross-layer solution for downlink cellular systems with
imperfect (and possibly no) CSI at the transmitter. We use rateless codes to
resolve channel uncertainty. To keep the decoding complexity low, we explicitly
incorporate time-average block-size constraints, and aim to maximize the system
utility. The block-size of a rateless code is determined by both the network
control decisions and the unknown CSI of many time slots. Therefore, unlike
standard utility maximization problems, this problem can be viewed as a
constrained partial observed Markov decision problem (CPOMDP), which is known
to be hard due to the "curse of dimensionality." However, by using a modified
Lyapunov drift method, we develop a dynamic network control scheme, which
yields a total network utility within O(1/Lav) of utility-optimal point
achieved by infinite block-size channel codes, where Lav is the enforced value
of the time-average block-size of rateless codes. This opens the door of being
able to trade complexity/delay for performance gains in the absence of accurate
CSI. Our simulation results show that the proposed scheme improves the network
throughput by up to 68% over schemes that use fixed-rate codes.


On the Critical Delays of Mobile Networks under Lévy Walks and
  Lévy Flights

  Delay-capacity tradeoffs for mobile networks have been analyzed through a
number of research work. However, L\'{e}vy mobility known to closely capture
human movement patterns has not been adopted in such work. Understanding the
delay-capacity tradeoff for a network with L\'{e}vy mobility can provide
important insights into understanding the performance of real mobile networks
governed by human mobility. This paper analytically derives an important point
in the delay-capacity tradeoff for L\'{e}vy mobility, known as the critical
delay. The critical delay is the minimum delay required to achieve greater
throughput than what conventional static networks can possibly achieve (i.e.,
$O(1/\sqrt{n})$ per node in a network with $n$ nodes). The L\'{e}vy mobility
includes L\'{e}vy flight and L\'{e}vy walk whose step size distributions
parametrized by $\alpha \in (0,2]$ are both heavy-tailed while their times
taken for the same step size are different. Our proposed technique involves (i)
analyzing the joint spatio-temporal probability density function of a
time-varying location of a node for L\'{e}vy flight and (ii) characterizing an
embedded Markov process in L\'{e}vy walk which is a semi-Markov process. The
results indicate that in L\'{e}vy walk, there is a phase transition such that
for $\alpha \in (0,1)$, the critical delay is always $\Theta (n^{1/2})$ and for
$\alpha \in [1,2]$ it is $\Theta(n^{\frac{\alpha}{2}})$. In contrast, L\'{e}vy
flight has the critical delay $\Theta(n^{\frac{\alpha}{2}})$ for
$\alpha\in(0,2]$.


Scheduling in Time-correlated Wireless Networks with Imperfect CSI and
  Stringent Constraint

  In a wireless network, the efficiency of scheduling algorithms over
time-varying channels depends heavily on the accuracy of the Channel State
Information (CSI), which is usually quite ``costly'' in terms of consuming
network resources. Scheduling in such systems is also subject to stringent
constraints such as power and bandwidth, which limit the maximum number of
simultaneous transmissions. In the meanwhile, communication channels in
wireless systems typically fluctuate in a time-correlated manner. We hence
design schedulers to exploit the temporal-correlation inherent in channels with
memory and ARQ-styled feedback from the users for better channel state
knowledge, under the assumption of Markovian channels and the stringent
constraint on the maximum number of simultaneously active users. We model this
problem under the framework of a Partially Observable Markov Decision
Processes.
  In recent work, a low-complexity optimal solution was developed for this
problem under a long-term time-average resource constraint. However, in real
systems with instantaneous resource constraints, how to optimally exploit the
temporal correlation and satisfy realistic stringent constraint on the
instantaneous service remains elusive. In this work, we incorporate a stringent
constraint on the simultaneously scheduled users and propose a low-complexity
scheduling algorithm that dynamically implements user scheduling and dummy
packet broadcasting. We show that the throughput region of the optimal policy
under the long-term average resource constraint can be asymptotically achieved
in the stringent constrained scenario by the proposed algorithm, in the many
users limiting regime.


Achieving Delay Rate-function Optimality in OFDM Downlink with
  Time-correlated Channels

  There have been recent attempts to develop scheduling schemes for downlink
transmission in a single cell of a multi-channel (e.g., OFDM-based) cellular
network. These works have been quite promising in that they have developed
low-complexity index scheduling policies that are delay-optimal (in a large
deviation rate-function sense). However, these policies require that the
channel is ON or OFF in each time-slot with a fixed probability (i.e., there is
no memory in the system), while the reality is that due to channel fading and
doppler shift, channels are often time-correlated in these cellular systems.
Thus, an important open question is whether one can find simple index
scheduling policies that are delay-optimal even when the channels are
time-correlated. In this paper, we attempt to answer this question for
time-correlated ON/OFF channels. In particular, we show that the class of
oldest packets first (OPF) policies that give a higher priority to packets with
a large delay is delay rate-function optimal under two conditions: 1) The
channel is non-negatively correlated, and 2) The distribution of the OFF period
is geometric. We use simulations to further elucidate the theoretical results.


Optimizing Data Freshness, Throughput, and Delay in Multi-Server
  Information-Update Systems

  In this work, we investigate the design of information-update systems, where
incoming update packets are forwarded to a remote destination through multiple
servers (each server can be viewed as a wireless channel). One important
performance metric of these systems is the age-of-information or simply age,
which is defined as the time elapsed since the freshest packet at the
destination was generated. Recent studies on information-update systems have
shown that the age-of-information can be reduced by intelligently dropping
stale packets. However, packet dropping may not be appropriate in many
applications, such as news and social updates, where users are interested in
not just the latest updates, but also past news. Therefore, all packets may
need to be successfully delivered. In this paper, we study how to optimize
age-of-information without throughput loss. We consider a general scenario
where incoming update packets do not necessarily arrive in the order of their
generation times. We prove that a preemptive Last Generated First Served (LGFS)
policy simultaneous optimizes the age, throughput, and delay performance in
infinite buffer queueing systems. We also show age-optimality for the LGFS
policy for any finite queue size. These results hold for arbitrary, including
non-stationary, arrival processes. To the best of our knowledge, this paper
presents the first optimal result on minimizing the age-of-information in
communication networks with an external arrival process of information update
packets.


On Delay-Optimal Scheduling in Queueing Systems with Replications

  In modern computer systems, jobs are divided into short tasks and executed in
parallel. Empirical observations in practical systems suggest that the task
service times are highly random and the job service time is bottlenecked by the
slowest straggling task. One common solution for straggler mitigation is to
replicate a task on multiple servers and wait for one replica of the task to
finish early. The delay performance of replications depends heavily on the
scheduling decisions of when to replicate, which servers to replicate on, and
which job to serve first. So far, little is understood on how to optimize these
scheduling decisions for minimizing the delay to complete the jobs. In this
paper, we present a comprehensive study on delay-optimal scheduling of
replications in both centralized and distributed multi-server systems.
Low-complexity scheduling policies are designed and are proven to be
delay-optimal or near delay-optimal in stochastic ordering among all causal and
non-preemptive policies. These theoretical results are established for general
system settings and delay metrics that allow for arbitrary arrival processes,
arbitrary job sizes, arbitrary due times, and heterogeneous servers with data
locality constraints. Novel sample-path tools are developed to prove these
results.


Reward Maximization Under Uncertainty: Leveraging Side-Observations on
  Networks

  We study the stochastic multi-armed bandit (MAB) problem in the presence of
side-observations across actions that occur as a result of an underlying
network structure. In our model, a bipartite graph captures the relationship
between actions and a common set of unknowns such that choosing an action
reveals observations for the unknowns that it is connected to. This models a
common scenario in online social networks where users respond to their friends'
activity, thus providing side information about each other's preferences. Our
contributions are as follows: 1) We derive an asymptotic lower bound (with
respect to time) as a function of the bi-partite network structure on the
regret of any uniformly good policy that achieves the maximum long-term average
reward. 2) We propose two policies - a randomized policy; and a policy based on
the well-known upper confidence bound (UCB) policies - both of which explore
each action at a rate that is a function of its network position. We show,
under mild assumptions, that these policies achieve the asymptotic lower bound
on the regret up to a multiplicative factor, independent of the network
structure. Finally, we use numerical examples on a real-world social network
and a routing example network to demonstrate the benefits obtained by our
policies over other existing policies.


Provably Delay Efficient Data Retrieving in Storage Clouds

  One key requirement for storage clouds is to be able to retrieve data
quickly. Recent system measurements have shown that the data retrieving delay
in storage clouds is highly variable, which may result in a long latency tail.
One crucial idea to improve the delay performance is to retrieve multiple data
copies by using parallel downloading threads. However, how to optimally
schedule these downloading threads to minimize the data retrieving delay
remains to be an important open problem. In this paper, we develop
low-complexity thread scheduling policies for several important classes of data
downloading time distributions, and prove that these policies are either
delay-optimal or within a constant gap from the optimum delay performance.
These theoretical results hold for an arbitrary arrival process of read
requests that may contain finite or infinite read requests, and for
heterogeneous MDS storage codes that can support diverse storage redundancy and
reliability requirements for different data files. Our numerical results show
that the delay performance of the proposed policies is significantly better
than that of First-Come- First-Served (FCFS) policies considered in prior work.


The Impact of Stealthy Attacks on Smart Grid Performance: Tradeoffs and
  Implications

  The smart grid is envisioned to significantly enhance the efficiency of
energy consumption, by utilizing two-way communication channels between
consumers and operators. For example, operators can opportunistically leverage
the delay tolerance of energy demands in order to balance the energy load over
time, and hence, reduce the total operational cost. This opportunity, however,
comes with security threats, as the grid becomes more vulnerable to
cyber-attacks. In this paper, we study the impact of such malicious
cyber-attacks on the energy efficiency of the grid in a simplified setup. More
precisely, we consider a simple model where the energy demands of the smart
grid consumers are intercepted and altered by an active attacker before they
arrive at the operator, who is equipped with limited intrusion detection
capabilities. We formulate the resulting optimization problems faced by the
operator and the attacker and propose several scheduling and attack strategies
for both parties. Interestingly, our results show that, as opposed to
facilitating cost reduction in the smart grid, increasing the delay tolerance
of the energy demands potentially allows the attacker to force increased costs
on the system. This highlights the need for carefully constructed and robust
intrusion detection mechanisms at the operator.


Defending Against Stealthy Attacks on Multiple Nodes with Limited
  Resources: A Game-Theoretic Analysis

  Stealthy attacks are a major cyber-security threat. In practice, both
attackers and defenders have resource constraints that could limit their
capabilities. Hence, to develop robust defense strategies, a promising approach
is to utilize game theory to understand the fundamental trade-offs involved.
Previous works in this direction, however, mainly focus on the single-node case
without considering strict resource constraints. In this paper, a
game-theoretic model for protecting a system of multiple nodes against stealthy
attacks is proposed. We consider the practical setting where the frequencies of
both attack and defense are constrained by limited resources, and an asymmetric
feedback structure where the attacker can fully observe the states of nodes
while largely hiding its actions from the defender. We characterize the best
response strategies for both attacker and defender in the space of both
non-adaptive and adaptive strategies, and study the Nash Equilibria of the
game. We further study a sequential game where the defender first announces its
strategy and the attacker then responds accordingly, and design an algorithm
that finds a nearly optimal strategy for the defender to commit to.


Delay-Optimal Buffer-Aware Scheduling with Adaptive Transmission

  In this work, we aim to obtain the optimal tradeoff between the average delay
and the average power consumption in a communication system. In our system, the
arrivals occur at each timeslot according to a Bernoulli arrival process and
are buffered at the transmitter. The transmitter determines the scheduling
policy of how many packets to transmit under an average power constraint. The
power is assumed to be an increasing and convex function of the number of
packets transmitted in each timeslot to capture the realism in communication
systems. We also consider a finite buffer and allow the scheduling decision to
depend on the buffer occupancy. This problem is modelled as a Constrained
Markov Decision Process (CMDP). We first prove that the optimal policy of the
(Lagrangian) relaxation of the CMDP is deterministic and threshold-based. We
then show that the optimal delay-power tradeoff curve is convex and piecewise
linear, where each of the vertices are obtained by the optimal solution to the
relaxed problem. This allows us to show the optimal policies of the CMDP are
threshold-based, and hence can be implemented by a proposed efficient
algorithm. The theoretical results and the algorithm are validated by Linear
Programming and simulations.


When to Reset Your Keys: Optimal Timing of Security Updates via Learning

  Cybersecurity is increasingly threatened by advanced and persistent attacks.
As these attacks are often designed to disable a system (or a critical
resource, e.g., a user account) repeatedly, it is crucial for the defender to
keep updating its security measures to strike a balance between the risk of
being compromised and the cost of security updates. Moreover, these decisions
often need to be made with limited and delayed feedback due to the stealthy
nature of advanced attacks. In addition to targeted attacks, such an optimal
timing policy under incomplete information has broad applications in
cybersecurity. Examples include key rotation, password change, application of
patches, and virtual machine refreshing. However, rigorous studies of optimal
timing are rare. Further, existing solutions typically rely on a pre-defined
attack model that is known to the defender, which is often not the case in
practice. In this work, we make an initial effort towards achieving optimal
timing of security updates in the face of unknown stealthy attacks. We consider
a variant of the influential FlipIt game model with asymmetric feedback and
unknown attack time distribution, which provides a general model to consecutive
security updates. The defender's problem is then modeled as a time associative
bandit problem with dependent arms. We derive upper confidence bound based
learning policies that achieve low regret compared with optimal periodic
defense strategies that can only be derived when attack time distributions are
known.


Dual Sub-6 GHz -- Millimeter Wave Beamforming and Communications to
  Achieve Low Latency and High Energy Efficiency in 5G Systems

  We propose a hybrid architecture that integrates RF (i.e., sub-6 GHz) and
millimeter wave (mmWave) technologies for 5G cellular systems. In particular,
communications in the mmWave band faces significant challenges due to variable
channels, intermittent connectivity, and high energy usage. On the other hand,
speeds for electronic processing of data is of the same order as typical rates
for mmWave interfaces which makes the use of complex algorithms for tracking
channel variations and adjusting resources accordingly impractical. Our
proposed architecture integrates the RF and mmWave interfaces for beamforming
and data transfer, and exploits the spatio-temporal correlations between the
interfaces. Based on extensive experimentation in indoor and outdoor settings,
we demonstrate that an integrated RF/mmWave signaling and channel estimation
scheme can remedy the problem of high energy usage and delay associated with
mmWave beamforming. In addition, cooperation between two interfaces at the
higher layers effectively addresses the high delays caused by highly
intermittent mmWave connectivity. We design a scheduler that fully exploits the
mmWave bandwidth, while the RF link acts as a fallback mechanism to prevent
high delay. To this end, we formulate an optimal scheduling problem over the RF
and mmWave interfaces where the goal is to maximize the delay-constrained
throughput of the mmWave interface. We prove using subadditivity analysis that
the optimal scheduling policy is based on a single threshold that can be easily
adopted despite high link variations.


Minimizing the Age of Information through Queues

  In this paper, we focus on developing simple scheduling policies that can
minimize the age of the information sent through multi-server queueing systems.
We consider a general packet arrival process, where the generation times and
arrival times of the packets are arbitrary. Hence, the packets may arrive in an
order that is different from the order of their generation times. Further, a
packet can be replicated on multiple servers, and one can specify a priori the
maximum number of replicas that can be created for each packet. Once a replica
is completed, the remaining replicas of this packet are canceled to release the
servers. We prove that simple variants (e.g., preemptive, replicative,
non-replicative) of the Last-Generated, First-Serve (LGFS) scheduling policy
are age-optimal in a stochastic ordering sense for exponentially distributed
packet service times. These policies are optimal for minimizing not only the
age process, but also for minimizing any non-decreasing functional of the age
process. We further investigate the class of New-Better-than-Used (NBU) service
time distributions and develop scheduling policies that are shown to be within
a constant gap from the optimum age performance. It is known that replication
worsens the delay and decreases the throughput for most NBU service time
distributions. However, to our surprise, we find that replication can in fact
reduce the age for a variety of NBU service time distributions. Our results
further imply that the variants of Last-Come, First-Serve (LCFS) scheduling
policies are (near) age-optimal, because they are special cases of the proposed
LGFS-type policies.


Energy-Efficient Power and Bandwidth Allocation in an Integrated Sub-6
  GHz -- Millimeter Wave System

  In mobile millimeter wave (mmWave) systems, energy is a scarce resource due
to the large losses in the channel and high energy usage by analog-to-digital
converters (ADC), which scales with bandwidth. In this paper, we consider a
communication architecture that integrates the sub-6 GHz and mmWave
technologies in 5G cellular systems. In order to mitigate the energy scarcity
in mmWave systems, we investigate the rate-optimal and energy-efficient
physical layer resource allocation jointly across the sub-6 GHz and mmWave
interfaces. First, we formulate an optimization problem in which the objective
is to maximize the achievable sum rate under power constraints at the
transmitter and receiver. Our formulation explicitly takes into account the
energy consumption in integrated-circuit components, and assigns the optimal
power and bandwidth across the interfaces. We consider the settings with no
channel state information and partial channel state information at the
transmitter and under high and low SNR scenarios. Second, we investigate the
energy efficiency (EE) defined as the ratio between the amount of data
transmitted and the corresponding incurred cost in terms of power. We use
fractional programming and Dinkelbach's algorithm to solve the EE optimization
problem. Our results prove that despite the availability of huge bandwidths at
the mmWave interface, it may be optimal (in terms of achievable sum rate and
energy efficiency) to utilize it partially. Moreover, depending on the sub-6
GHz and mmWave channel conditions and total power budget, it may be optimal to
activate only one of the interfaces.


Efficient Beam Alignment in Millimeter Wave Systems Using Contextual
  Bandits

  In this paper, we investigate the problem of beam alignment in millimeter
wave (mmWave) systems, and design an optimal algorithm to reduce the overhead.
Specifically, due to directional communications, the transmitter and receiver
beams need to be aligned, which incurs high delay overhead since without a
priori knowledge of the transmitter/receiver location, the search space spans
the entire angular domain. This is further exacerbated under dynamic conditions
(e.g., moving vehicles) where the access to the base station (access point) is
highly dynamic with intermittent on-off periods, requiring more frequent beam
alignment and signal training. To mitigate this issue, we consider an online
stochastic optimization formulation where the goal is to maximize the
directivity gain (i.e., received energy) of the beam alignment policy within a
time period. We exploit the inherent correlation and unimodality properties of
the model, and demonstrate that contextual information improves the
performance. To this end, we propose an equivalent structured Multi-Armed
Bandit model to optimally exploit the exploration-exploitation tradeoff. In
contrast to the classical MAB models, the contextual information makes the
lower bound on regret (i.e., performance loss compared with an oracle policy)
independent of the number of beams. This is a crucial property since the number
of all combinations of beam patterns can be large in transceiver antenna
arrays, especially in massive MIMO systems. We further provide an
asymptotically optimal beam alignment algorithm, and investigate its
performance via simulations.


The Age of Information in Multihop Networks

  The problem of minimizing the age-of-information has been extensively studied
in single-hop networks. In this paper, we minimize the age of a single
information flow in multihop networks. If the packet transmission times over
the network links are exponentially distributed, we prove that a preemptive
Last-Generated, First-Serve (LGFS) policy results in smaller age processes at
all nodes of the network (in a stochastic ordering sense) than any other causal
policy. In addition, for arbitrary distributions of packet transmission times,
the non-preemptive LGFS policy is shown to minimize the age processes at all
nodes among all non-preemptive work-conserving policies (again in a stochastic
ordering sense). Interestingly, these simple policies can achieve optimality of
the joint distribution of the age processes at all nodes even under arbitrary
network topologies, as well as arbitrary packet generation and arrival times.
These optimality results not only hold for the age processes, but also for any
non-decreasing functional of the age processes. Finally, we investigate the
class of New-Better-than-Used (NBU) packet transmission time distributions and
show that the non-preemptive LGFS policy is within a constant age gap from the
optimum average age, and that the gap is independent of system parameters.


High Throughput Low Delay Wireless Multicast via Multi-Channel Moving
  Window Codes

  A fundamental challenge in wireless multicast has been how to simultaneously
achieve high-throughput and low-delay for reliably serving a large number of
users. In this paper, we show how to harness substantial throughput and delay
gains by exploiting multi-channel resources. We develop a new scheme called
Multi-Channel Moving Window Codes (MC-MWC) for multi-channel multi-session
wireless multicast. The salient features of MC-MWC are three-fold. (i) High
throughput: we show that MC-MWC achieves order-optimal throughput in the
many-user many-channel asymptotic regime. Moreover, the number of channels
required by a conventional channel-allocation based scheme is shown to be
doubly-exponentially larger than that required by MC-MWC. (ii) Low delay: using
large deviations theory, we show that the delay of MC-MWC decreases linearly
with the number of channels, while the delay reduction of conventional schemes
is no more than a finite constant. (iii) Low feedback overhead: the feedback
overhead of MC-MWC is a constant that is independent of both the number of
receivers in each session and the number of sessions in the network. Finally,
our trace-driven simulation and numerical results validate the analytical
results and show that the implementation complexity of MC-MWC is low.


PAC Ranking from Pairwise and Listwise Queries: Lower Bounds and Upper
  Bounds

  This paper explores the adaptive (active) PAC (probably approximately
correct) top-$k$ ranking (i.e., top-$k$ item selection) and total ranking
problems from $l$-wise ($l\geq 2$) comparisons under the multinomial logit
(MNL) model. By adaptively choosing sets to query and observing the noisy
output of the most favored item of each query, we want to design ranking
algorithms that recover the top-$k$ or total ranking using as few queries as
possible. For the PAC top-$k$ ranking problem, we derive a lower bound on the
sample complexity (aka number of queries), and propose an algorithm that is
sample-complexity-optimal up to an $O(\log(k+l)/\log{k})$ factor. When $l=2$
(i.e., pairwise comparisons) or $l=O(poly(k))$, this algorithm matches the
lower bound. For the PAC total ranking problem, we derive a tight lower bound,
and propose an algorithm that matches the lower bound. When $l=2$, the MNL
model reduces to the popular Plackett-Luce (PL) model. In this setting, our
results still outperform the state-of-the-art both theoretically and
numerically. We also compare our algorithms with the state-of-the-art using
synthetic data as well as real-world data to verify the efficiency of our
algorithms.


Simulated Annealing for Optimal Resource Allocation in Wireless Networks
  with ImperfectCommunications

  Simulated annealing (SA) method has had significant recent success in
designing distributed control algorithms for wireless networks. These SA based
techniques formed the basis of new CSMA algorithms and gave rise to the
development of numerous variants to achieve the best system performance
accommodating different communication technologies and more realistic system
conditions. However, these algorithms do not readily extend to networks with
noisy environments, as unreliable communication prevents them from gathering
the necessary system state information needed to execute the algorithm. In
recognition of this challenge, we propose a new SA algorithm that is designed
to work more robustly in networks with communications that experience frequent
message drops. The main idea of the proposed algorithm is a novel coupling
technique that takes into account the external randomness of message passing
failure events as a part of probabilistic uncertainty inherent in stochastic
acceptance criterion of SA. As a result, the algorithm can be executed even
with partial observation of system states, which was not possible under the
traditional SA approach. We show that the newly proposed algorithm finds the
optimal solution almost surely under the standard annealing framework while
offering significant performance benefits in terms of its computational speed
in the presence of frequent message drops.


Age-optimal Sampling and Transmission Scheduling in Multi-Source Systems

  In this paper, we consider the problem of minimizing the age of information
in a multi-source system, where sources communicate their update packets to a
destination via a channel with random delay. Due to interference, only one
source can be scheduled at a time. We consider the problem of finding a
decision policy that controls the packet sampling times and schedules source
transmissions to minimize the total average peak age (TaPA) and the total
average age (TaA) of the sources. Our investigation of this problem results in
an important separation principle: The optimal scheduling strategy and the
optimal sampling strategy are independent of each other. In particular, we
prove that, given the sampling times of the update packets, the Maximum Age
First (MAF) scheduling strategy provides the best age performance among all
scheduling strategies. This transforms our overall optimization problem into an
optimal sampling problem, given that the decision policy follows the MAF
scheduling strategy. Interestingly, we show that the zero-wait sampler (in
which a packet is generated once the channel is idle) is optimal for minimizing
the TaPA, while it does not always minimize the TaA. We use Dynamic Programming
(DP) to investigate the optimal sampler for minimizing the TaA. Finally, we
provide an approximate analysis of Bellman's equation to approximate the
TaA-optimal sampler by a water-filling solution and demonstrate its efficacy
through numerical evaluations.


Integrating Sub-6 GHz and Millimeter Wave to Combat Blockage:
  Delay-Optimal Scheduling

  Millimeter wave (mmWave) technologies have the potential to achieve very high
data rates, but suffer from intermittent connectivity. In this paper, we
provision an architecture to integrate sub-6 GHz and mmWave technologies, where
we incorporate the sub-6 GHz interface as a fallback data transfer mechanism to
combat blockage and intermittent connectivity of the mmWave communications. To
this end, we investigate the problem of scheduling data packets across the
mmWave and sub-6 GHz interfaces such that the average delay of system is
minimized. This problem can be formulated as Markov Decision Process. We first
investigate the problem of discounted delay minimization, and prove that the
optimal policy is of the threshold-type, i.e., data packets should always be
routed to the mmWave interface as long as the number of packets in the system
is smaller than a threshold. Then, we show that the results of the discounted
delay problem hold for the average delay problem as well. Through numerical
results, we demonstrate that under heavy traffic, integrating sub-6 GHz with
mmWave can reduce the average delay by up to 70%. Further, our scheduling
policy substantially reduces the delay over the celebrated MaxWeight policy.


Achieving Optimal Throughput and Near-Optimal Asymptotic Delay
  Performance in Multi-Channel Wireless Networks with Low Complexity: A
  Practical Greedy Scheduling Policy

  In this paper, we focus on the scheduling problem in multi-channel wireless
networks, e.g., the downlink of a single cell in fourth generation (4G)
OFDM-based cellular networks. Our goal is to design practical scheduling
policies that can achieve provably good performance in terms of both throughput
and delay, at a low complexity. While a class of $O(n^{2.5} \log n)$-complexity
hybrid scheduling policies are recently developed to guarantee both
rate-function delay optimality (in the many-channel many-user asymptotic
regime) and throughput optimality (in the general non-asymptotic setting),
their practical complexity is typically high. To address this issue, we develop
a simple greedy policy called Delay-based Server-Side-Greedy (D-SSG) with a
\lower complexity $2n^2+2n$, and rigorously prove that D-SSG not only achieves
throughput optimality, but also guarantees near-optimal asymptotic delay
performance. Specifically, we show that the rate-function attained by D-SSG for
any delay-violation threshold $b$, is no smaller than the maximum achievable
rate-function by any scheduling policy for threshold $b-1$. Thus, we are able
to achieve a reduction in complexity (from $O(n^{2.5} \log n)$ of the hybrid
policies to $2n^2 + 2n$) with a minimal drop in the delay performance. More
importantly, in practice, D-SSG generally has a substantially lower complexity
than the hybrid policies that typically have a large constant factor hidden in
the $O(\cdot)$ notation. Finally, we conduct numerical simulations to validate
our theoretical results in various scenarios. The simulation results show that
D-SSG not only guarantees a near-optimal rate-function, but also empirically is
virtually indistinguishable from delay-optimal policies.


Multiuser Scheduling in a Markov-modeled Downlink using Randomly Delayed
  ARQ Feedback

  We focus on the downlink of a cellular system, which corresponds to the bulk
of the data transfer in such wireless systems. We address the problem of
opportunistic multiuser scheduling under imperfect channel state information,
by exploiting the memory inherent in the channel. In our setting, the channel
between the base station and each user is modeled by a two-state Markov chain
and the scheduled user sends back an ARQ feedback signal that arrives at the
scheduler with a random delay that is i.i.d across users and time. The
scheduler indirectly estimates the channel via accumulated delayed-ARQ feedback
and uses this information to make scheduling decisions. We formulate a
throughput maximization problem as a partially observable Markov decision
process (POMDP). For the case of two users in the system, we show that a greedy
policy is sum throughput optimal for any distribution on the ARQ feedback
delay. For the case of more than two users, we prove that the greedy policy is
suboptimal and demonstrate, via numerical studies, that it has near optimal
performance. We show that the greedy policy can be implemented by a simple
algorithm that does not require the statistics of the underlying Markov channel
or the ARQ feedback delay, thus making it robust against errors in system
parameter estimation. Establishing an equivalence between the two-user system
and a genie-aided system, we obtain a simple closed form expression for the sum
capacity of the Markov-modeled downlink. We further derive inner and outer
bounds on the capacity region of the Markov-modeled downlink and tighten these
bounds for special cases of the system parameters.


Exploiting Channel Memory for Joint Estimation and Scheduling in
  Downlink Networks

  We address the problem of opportunistic multiuser scheduling in downlink
networks with Markov-modeled outage channels. We consider the scenario in which
the scheduler does not have full knowledge of the channel state information,
but instead estimates the channel state information by exploiting the memory
inherent in the Markov channels along with ARQ-styled feedback from the
scheduled users. Opportunistic scheduling is optimized in two stages: (1)
Channel estimation and rate adaptation to maximize the expected immediate rate
of the scheduled user; (2) User scheduling, based on the optimized immediate
rate, to maximize the overall long term sum-throughput of the downlink. The
scheduling problem is a partially observable Markov decision process with the
classic 'exploitation vs exploration' trade-off that is difficult to quantify.
We therefore study the problem in the framework of Restless Multi-armed Bandit
Processes (RMBP) and perform a Whittle's indexability analysis. Whittle's
indexability is traditionally known to be hard to establish and the index
policy derived based on Whittle's indexability is known to have optimality
properties in various settings. We show that the problem of downlink scheduling
under imperfect channel state information is Whittle indexable and derive the
Whittle's index policy in closed form. Via extensive numerical experiments, we
show that the index policy has near-optimal performance.
  Our work reveals that, under incomplete channel state information, exploiting
channel memory for opportunistic scheduling can result in significant
performance gains and that almost all of these gains can be realized using an
easy-to-implement index policy.


Downlink Scheduling over Markovian Fading Channels

  We consider the scheduling problem in downlink wireless networks with
heterogeneous, Markov-modulated, ON/OFF channels. It is well-known that the
performance of scheduling over fading channels relies heavily on the accuracy
of the available Channel State Information (CSI), which is costly to acquire.
Thus, we consider the CSI acquisition via a practical ARQ-based feedback
mechanism whereby channel states are revealed at the end of only scheduled
users' transmissions. In the assumed presence of temporally-correlated channel
evolutions, the desired scheduler must optimally balance the
exploitation-exploration trade-off, whereby it schedules transmissions both to
exploit those channels with up-to-date CSI and to explore the current state of
those with outdated CSI.
  In earlier works, Whittle's Index Policy had been suggested as a
low-complexity and high-performance solution to this problem. However,
analyzing its performance in the typical scenario of statistically
heterogeneous channel state processes has remained elusive and challenging,
mainly because of the highly-coupled and complex dynamics it possesses. In this
work, we overcome these difficulties to rigorously establish the asymptotic
optimality properties of Whittle's Index Policy in the limiting regime of many
users. More specifically: (1) we prove the local optimality of Whittle's Index
Policy, provided that the initial state of the system is within a certain
neighborhood of a carefully selected state; (2) we then establish the global
optimality of Whittle's Index Policy under a recurrence assumption that is
verified numerically for our problem. These results establish that Whittle's
Index Policy possesses analytically provable optimality characteristics for
scheduling over heterogeneous and temporally-correlated channels.


